{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lollipop6370/ML2025/blob/main/MLhw1_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TFwaJir_Olj"
      },
      "source": [
        "# ML2025 Homework 1 - Retrieval Augmented Generation with Agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tQHdH2k_Olk"
      },
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will mount your own Google Drive and change the working directory."
      ],
      "metadata": {
        "id": "-_ZkNxqGGhdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DWQh-lq8GuwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5810b10-3441-41fb-9067-f2d684156746"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the working directory to somewhere in your Google Drive.\n",
        "# You could check the path by right clicking on the folder.\n",
        "%cd /content/drive/MyDrive/ML"
      ],
      "metadata": {
        "id": "P_5Tf1rMHBQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e84741fc-594c-4f4a-8870-5f8bfc863f84"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGx000oZ_Oll"
      },
      "source": [
        "In this section, we install the necessary python packages and download model weights of the quantized version of LLaMA 3.1 8B. Also, download the dataset. Note that the model weight is around 8GB. If you are using your Google Drive as the working directory, make sure you have enough space for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5JywoPOO_Oll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "089e4057-98c2-4881-b36b-5e6d950b28f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://abetlen.github.io/llama-cpp-python/whl/cu122\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (10.4)\n",
            "Collecting websockets\n",
            "  Downloading websockets-15.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: llama-cpp-python==0.3.4 in /usr/local/lib/python3.11/dist-packages (0.3.4)\n",
            "Requirement already satisfied: googlesearch-python in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.11/dist-packages (0.0.2)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
            "Requirement already satisfied: requests-html in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
            "Requirement already satisfied: lxml_html_clean in /usr/local/lib/python3.11/dist-packages (0.4.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python==0.3.4) (4.14.1)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python==0.3.4) (2.0.2)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python==0.3.4) (5.6.3)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.11/dist-packages (from llama-cpp-python==0.3.4) (3.1.6)\n",
            "Requirement already satisfied: beautifulsoup4>=4.9 in /usr/local/lib/python3.11/dist-packages (from googlesearch-python) (4.13.4)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from googlesearch-python) (2.32.3)\n",
            "Requirement already satisfied: pyquery in /usr/local/lib/python3.11/dist-packages (from requests-html) (2.0.1)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.11/dist-packages (from requests-html) (2.2.0)\n",
            "Requirement already satisfied: parse in /usr/local/lib/python3.11/dist-packages (from requests-html) (1.20.2)\n",
            "Requirement already satisfied: w3lib in /usr/local/lib/python3.11/dist-packages (from requests-html) (2.3.1)\n",
            "Requirement already satisfied: pyppeteer>=0.0.14 in /usr/local/lib/python3.11/dist-packages (from requests-html) (2.0.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from lxml_html_clean) (5.4.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.11.3->llama-cpp-python==0.3.4) (3.0.2)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2023 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (2025.7.14)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (8.7.0)\n",
            "Requirement already satisfied: pyee<12.0.0,>=11.0.0 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (11.1.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (4.67.1)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /usr/local/lib/python3.11/dist-packages (from pyppeteer>=0.0.14->requests-html) (1.26.20)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->googlesearch-python) (3.10)\n",
            "Requirement already satisfied: cssselect>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyquery->requests-html) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.23.0)\n"
          ]
        }
      ],
      "source": [
        "#!python3 -m pip install --no-cache-dir llama-cpp-python==0.3.4 --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu122\n",
        "#!python3 -m pip install googlesearch-python bs4 charset-normalizer requests-html lxml_html_clean\n",
        "\n",
        "# 一次性安裝所有套件並升級 websockets\n",
        "!python3 -m pip install --upgrade websockets llama-cpp-python==0.3.4 googlesearch-python bs4 charset-normalizer requests-html lxml_html_clean --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu122\n",
        "\n",
        "from pathlib import Path\n",
        "if not Path('./Meta-Llama-3.1-8B-Instruct-Q8_0.gguf').exists():\n",
        "    !wget https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf\n",
        "if not Path('./public.txt').exists():\n",
        "    !wget https://www.csie.ntu.edu.tw/~ulin/public.txt\n",
        "if not Path('./private.txt').exists():\n",
        "    !wget https://www.csie.ntu.edu.tw/~ulin/private.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kX6SizAt_Olm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "672657b2-178d-47ba-fad6-a36cd8c403f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are good to go!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "if not torch.cuda.is_available():\n",
        "    raise Exception('You are not using the GPU runtime. Change it first or you will suffer from the super slow inference speed!')\n",
        "else:\n",
        "    print('You are good to go!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3iyc1qC_Olm"
      },
      "source": [
        "## Prepare the LLM and LLM utility function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T59vxAo2_Olm"
      },
      "source": [
        "By default, we will use the quantized version of LLaMA 3.1 8B. you can get full marks on this homework by using the provided LLM and LLM utility function. You can also try out different LLM models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtepTeT3_Olm"
      },
      "source": [
        "In the following code block, we will load the downloaded LLM model weights onto the GPU first.\n",
        "Then, we implemented the generate_response() function so that you can get the generated response from the LLM model more easily."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVil2Vhe_Olm"
      },
      "source": [
        "You can ignore \"llama_new_context_with_model: n_ctx_per_seq (16384) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\" warning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ScyW45N__Olm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c89dd30-9c41-46bd-b160-ed0439ad31f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_new_context_with_model: n_ctx_per_seq (16384) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n"
          ]
        }
      ],
      "source": [
        "from llama_cpp import Llama\n",
        "\n",
        "# Load the model onto GPU\n",
        "llama3 = Llama(\n",
        "    \"./Meta-Llama-3.1-8B-Instruct-Q8_0.gguf\",\n",
        "    verbose=False,\n",
        "    n_gpu_layers=-1,\n",
        "    n_ctx=16384,    # This argument is how many tokens the model can take. The longer the better, but it will consume more memory. 16384 is a proper value for a GPU with 16GB VRAM.\n",
        ")\n",
        "\n",
        "def generate_response(_model: Llama, _messages: str) -> str:\n",
        "    '''\n",
        "    This function will inference the model with given messages.\n",
        "    '''\n",
        "    _messages = _messages[:16383]\n",
        "    _output = _model.create_chat_completion(\n",
        "        _messages,\n",
        "        stop=[\"<|eot_id|>\", \"<|end_of_text|>\"],\n",
        "        max_tokens=512,    # This argument is how many tokens the model can generate, you can change it and observe the differences.\n",
        "        temperature=0,      # This argument is the randomness of the model. 0 means no randomness. You will get the same result with the same input every time. You can try to set it to different values.\n",
        "        repeat_penalty=2.0,\n",
        "    )[\"choices\"][0][\"message\"][\"content\"]\n",
        "    return _output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnHLwq-4_Olm"
      },
      "source": [
        "## Search Tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYM-2ZsE_Olm"
      },
      "source": [
        "The TA has implemented a search tool for you to search certain keywords using Google Search. You can use this tool to search for the relevant **web pages** for the given question. The search tool can be integrated in the following sections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bEIRmZl7_Oln"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from googlesearch import search as _search\n",
        "from bs4 import BeautifulSoup\n",
        "from charset_normalizer import detect\n",
        "import asyncio\n",
        "from requests_html import AsyncHTMLSession\n",
        "import urllib3\n",
        "urllib3.disable_warnings()\n",
        "\n",
        "async def worker(s:AsyncHTMLSession, url:str):\n",
        "    try:\n",
        "        header_response = await asyncio.wait_for(s.head(url, verify=False), timeout=10)\n",
        "        if 'text/html' not in header_response.headers.get('Content-Type', ''):\n",
        "            return None\n",
        "        r = await asyncio.wait_for(s.get(url, verify=False), timeout=10)\n",
        "        return r.text\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "async def get_htmls(urls):\n",
        "    session = AsyncHTMLSession()\n",
        "    tasks = (worker(session, url) for url in urls)\n",
        "    return await asyncio.gather(*tasks)\n",
        "\n",
        "async def search(keyword: str, n_results: int=3) -> List[str]:\n",
        "    '''\n",
        "    This function will search the keyword and return the text content in the first n_results web pages.\n",
        "\n",
        "    Warning: You may suffer from HTTP 429 errors if you search too many times in a period of time. This is unavoidable and you should take your own risk if you want to try search more results at once.\n",
        "    The rate limit is not explicitly announced by Google, hence there's not much we can do except for changing the IP or wait until Google unban you (we don't know how long the penalty will last either).\n",
        "    '''\n",
        "    keyword = keyword[:100]\n",
        "    # First, search the keyword and get the results. Also, get 2 times more results in case some of them are invalid.\n",
        "    results = list(_search(keyword, n_results * 2, lang=\"zh\", unique=True))\n",
        "    # Then, get the HTML from the results. Also, the helper function will filter out the non-HTML urls.\n",
        "    results = await get_htmls(results)\n",
        "    # Filter out the None values.\n",
        "    results = [x for x in results if x is not None]\n",
        "    # Parse the HTML.\n",
        "    results = [BeautifulSoup(x, 'html.parser') for x in results]\n",
        "    # Get the text from the HTML and remove the spaces. Also, filter out the non-utf-8 encoding.\n",
        "    results = [''.join(x.get_text().split()) for x in results if detect(x.encode()).get('encoding') == 'utf-8']\n",
        "    # Return the first n results.\n",
        "    return results[:n_results]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC3zQjjj_Oln"
      },
      "source": [
        "## Test the LLM inference pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8dmGCARd_Oln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec72a604-28b6-495f-b8f2-0638622d0075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "泰勒絲（Taylor Swift）是一位美國歌手、詞曲作家和音樂製作人。她出生於1989年，來自田納西州。她的音乐风格从乡村摇滚发展到流行搖擺，並且她被誉为当代最成功的女艺人的之一。\n",
            "\n",
            "泰勒絲早期在鄉郊小鎮演唱會時開始發展音樂事業，她推出了多張專輯，包括《Taylor Swift》、《Fearless》，以及後來更為知名的大熱作如 《1989》（2014年）、_reputation（）和 _Lover （）。她的歌曲經常探討愛情、友誼及自我成長等主題。\n",
            "\n",
            "泰勒絲獲得了許多獎項，包括13座格萊美奖，並且是史上最快達到百萬銷量的女藝人之一。\n"
          ]
        }
      ],
      "source": [
        "# You can try out different questions here.\n",
        "test_question='請問誰是 Taylor Swift？'\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"你是 LLaMA-3.1-8B，是用來回答問題的 AI。使用中文時只會使用繁體中文來回問題。\"},    # System prompt\n",
        "    {\"role\": \"user\", \"content\": test_question}, # User prompt\n",
        "]\n",
        "\n",
        "print(generate_response(llama3, messages))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0-ojJuE_Oln"
      },
      "source": [
        "## Agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGsIPud3_Oln"
      },
      "source": [
        "The TA has implemented the Agent class for you. You can use this class to create agents that can interact with the LLM model. The Agent class has the following attributes and methods:\n",
        "- Attributes:\n",
        "    - role_description: The role of the agent. For example, if you want this agent to be a history expert, you can set the role_description to \"You are a history expert. You will only answer questions based on what really happened in the past. Do not generate any answer if you don't have reliable sources.\".\n",
        "    - task_description: The task of the agent. For example, if you want this agent to answer questions only in yes/no, you can set the task_description to \"Please answer the following question in yes/no. Explanations are not needed.\"\n",
        "    - llm: Just an indicator of the LLM model used by the agent.\n",
        "- Method:\n",
        "    - inference: This method takes a message as input and returns the generated response from the LLM model. The message will first be formatted into proper input for the LLM model. (This is where you can set some global instructions like \"Please speak in a polite manner\" or \"Please provide a detailed explanation\".) The generated response will be returned as the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zjG-UwDX_Oln"
      },
      "outputs": [],
      "source": [
        "class LLMAgent():\n",
        "    def __init__(self, role_description: str, task_description: str, llm:str=\"bartowski/Meta-Llama-3.1-8B-Instruct-GGUF\"):\n",
        "        self.role_description = role_description   # Role means who this agent should act like. e.g. the history expert, the manager......\n",
        "        self.task_description = task_description    # Task description instructs what task should this agent solve.\n",
        "        self.llm = llm  # LLM indicates which LLM backend this agent is using.\n",
        "    def inference(self, message:str, question=\"\") -> str:\n",
        "        if self.llm == 'bartowski/Meta-Llama-3.1-8B-Instruct-GGUF': # If using the default one.\n",
        "            # TODO: Design the system prompt and user prompt here.\n",
        "            # Format the messsages first.\n",
        "            messages = [\n",
        "                {\"role\": \"system\", \"content\": f\"{self.role_description}\\n{question}\"},  # Hint: you may want the agents to speak Traditional Chinese only.\n",
        "                {\"role\": \"user\", \"content\": f\"{self.task_description}\\n{message}\"}, # Hint: you may want the agents to clearly distinguish the task descriptions and the user messages. A proper seperation text rather than a simple line break is recommended.\n",
        "            ]\n",
        "            return generate_response(llama3, messages)\n",
        "        else:\n",
        "            # TODO: If you want to use LLMs other than the given one, please implement the inference part on your own.\n",
        "            return \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-ueJrgP_Oln"
      },
      "source": [
        "TODO: Design the role description and task description for each agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DzPzmNnj_Oln"
      },
      "outputs": [],
      "source": [
        "# TODO: Design the role and task description for each agent.\n",
        "\n",
        "# This agent may help you filter out the irrelevant parts in question descriptions.\n",
        "question_extraction_agent = LLMAgent(\n",
        "    role_description=\"你是提問大師，負責優化問題並精準命題，注意:問題不可以無中生有，要依照原題意思。必須遵循以下範例格式:\\n'題目:2025年台灣的牌照稅多少錢?\\n題目:3+8=?\\n題目:台大進階英文免修門檻要求 TOEFL iBT 達到多少分才能申請?'\",\n",
        "    task_description=\"請根據以下問題優化: \",\n",
        ")\n",
        "\n",
        "# This agent may help you extract the keywords in a question so that the search tool can find more accurate results.\n",
        "keyword_extraction_agent = LLMAgent(\n",
        "    role_description=\"你是搜尋引擎專家，負責找出問題中關鍵字用來給搜尋引擎查找資料。請給出關鍵字就好，不需要多做解釋。\",\n",
        "    task_description=\"請根據以下敘述找出關鍵字: \",\n",
        ")\n",
        "\n",
        "# summarize agent\n",
        "summarize_agent = LLMAgent(\n",
        "    role_description=\"你是總結專家，負責連接題目與文章敘述做出對題目合理的總結。你只需要詳細思考後給合理的結果，不要重複'總結'這兩個字。\",\n",
        "    task_description=\"請根據題目對以下敘述做總結: \",\n",
        ")\n",
        "\n",
        "# This agent is the core component that answers the question.\n",
        "qa_agent = LLMAgent(\n",
        "    role_description=\"你是 LLaMA-3.1-8B，是用來回答問題的 AI。使用中文時只會使用繁體中文來回問題，不可以使用簡體中文，遇到名字可以用英文。我會給你一些網路上關於此問題的總結資料，這些資訊可能會有部分錯誤，請看完每一段總結及給定的問題後，統整並詳細思考問題合理的答案，沒信心時就選你認為最可能的答案。只需要簡單回答答案就好，不要描述答案怎麼來的。\",\n",
        "    task_description=\"請回答以下問題：\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9eoywr7_Oln"
      },
      "source": [
        "## RAG pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HDOjNYJ_Oln"
      },
      "source": [
        "TODO: Implement the RAG pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRGNa-1i_Oln"
      },
      "source": [
        "Please refer to the homework description slides for hints.\n",
        "\n",
        "Also, there might be more heuristics (e.g. classifying the questions based on their lengths, determining if the question need a search or not, reconfirm the answer before returning it to the user......) that are not shown in the flow charts. You can use your creativity to come up with a better solution!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMaIsKAZ_Olo"
      },
      "source": [
        "- Naive approach (simple baseline)\n",
        "\n",
        "    ![](https://www.csie.ntu.edu.tw/~ulin/naive.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mppO-oOO_Olo"
      },
      "source": [
        "- Naive RAG approach (medium baseline)\n",
        "\n",
        "    ![](https://www.csie.ntu.edu.tw/~ulin/naive_rag.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYxbciLO_Olo"
      },
      "source": [
        "- RAG with agents (strong baseline)\n",
        "\n",
        "    ![](https://www.csie.ntu.edu.tw/~ulin/rag_agent.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ztJkA7R7_Olo"
      },
      "outputs": [],
      "source": [
        "async def pipeline(question: str) -> str:\n",
        "    # TODO: Implement your pipeline.\n",
        "\n",
        "    # question extraction agent\n",
        "    question = question_extraction_agent.inference(question)\n",
        "    print(question)\n",
        "\n",
        "    # keyward extraction agent\n",
        "    #keywards = keyword_extraction_agent.inference(question)\n",
        "    #print(\"K: \", keywards)\n",
        "\n",
        "    # use keywards to search\n",
        "    key_data = await search(question)\n",
        "    #print(key_answer)\n",
        "\n",
        "    # summarize agent\n",
        "    key_answer = []\n",
        "    print(\"summarize:\\n\")\n",
        "    for data in key_data:\n",
        "        summarize = summarize_agent.inference(data[:16384], question)\n",
        "        print(summarize + \"\\n\")\n",
        "        key_answer.append(summarize)\n",
        "\n",
        "    # merge question\n",
        "    augment_question = \"\\n\".join(key_answer) + \"\\n\" + question\n",
        "\n",
        "    # QA agent\n",
        "    return qa_agent.inference(augment_question)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer the questions using your pipeline!"
      ],
      "metadata": {
        "id": "P_kI_9EGB0S9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since Colab has usage limit, you might encounter the disconnections. The following code will save your answer for each question. If you have mounted your Google Drive as instructed, you can just rerun the whole notebook to continue your process."
      ],
      "metadata": {
        "id": "PN17sSZ8DUg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Fill in your student ID first.\n",
        "STUDENT_ID = \"n96141139\"\n",
        "\n",
        "STUDENT_ID = STUDENT_ID.lower()\n",
        "with open('./public.txt', 'r') as input_f:\n",
        "    questions = input_f.readlines()\n",
        "    questions = [l.strip().split(',')[0] for l in questions]\n",
        "    for id, question in enumerate(questions, 1):\n",
        "        if Path(f\"./{STUDENT_ID}_{id}.txt\").exists():\n",
        "            continue\n",
        "        answer = await pipeline(question)\n",
        "        answer = answer.replace('\\n',' ')\n",
        "        print(id, answer)\n",
        "        with open(f'./{STUDENT_ID}_{id}.txt', 'w') as output_f:\n",
        "            print(answer, file=output_f)\n",
        "\n",
        "with open('./private.txt', 'r') as input_f:\n",
        "    questions = input_f.readlines()\n",
        "    for id, question in enumerate(questions, 31):\n",
        "        if Path(f\"./{STUDENT_ID}_{id}.txt\").exists():\n",
        "            continue\n",
        "        answer = await pipeline(question)\n",
        "        answer = answer.replace('\\n',' ')\n",
        "        print(id, answer)\n",
        "        with open(f'./{STUDENT_ID}_{id}.txt', 'a') as output_f:\n",
        "            print(answer, file=output_f)"
      ],
      "metadata": {
        "id": "plUDRTi_B39S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aad1837-a780-45e3-ae99-f55ee27c27fc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "題目:「虎山雄風飛揚」是哪間學校的校歌？\n",
            "summarize:\n",
            "\n",
            "題目「虎山雄風飛揚」是哪間學校的校歌？\n",
            "\n",
            "根據提供的情況，答案為光華國小。\n",
            "\n",
            "根據題目「虎山雄風飛揚」是哪間學校的校歌？，可以得出以下結論：這是一首與某所學 校相關聯 的音樂作品。\n",
            "\n",
            "「虎山雄風飛揚」是南投縣光華國小的校歌。\n",
            "\n",
            "1 光華國小的校歌。\n",
            "題目:2025年初，NCC透過行政命令規定境外郵購自用產品（如無線鍑盤、滑鼠和藍芽耳機）回台的審查費為多少？\n",
            "summarize:\n",
            "\n",
            "根據NCC的公告，自2025年初起，如果境外郵購回台使用自己的產品（如無線鍑盤、滑鼠和藍芽耳機），需要繳交審查費高達750元。\n",
            "\n",
            "2025年初，NCC透過行政命令規定境外郵購自用產品（如無線鍑盤、滑鼠和藍芽耳機）回台的審查費為750元。\n",
            "\n",
            "2025年初，NCC透過行政命令規定境外郵購自用產品（如無線鍑盤、滑鼠和藍芽耳機）回台的審查費為750元。\n",
            "\n",
            "2 750元\n",
            "題目:第一代 iPhone 是由哪位蘋果 CEO 發表？\n",
            "summarize:\n",
            "\n",
            "第一代 iPhone 是由史蒂夫·乔布斯在 2007 年的 Macworld Conference & Expo 上发布，同年六月二十九日正式发售。\n",
            "\n",
            "第一代 iPhone 是由前蘋果公司 CEO 史蒂夫·乔布斯 發表的。\n",
            "\n",
            "賈伯斯SteveJobs是蘋果Apple的創辦人，他在2007年MacWorldExpo上首次發表初代iPhone，改變了手機和通訊方式。\n",
            "\n",
            "3 第一代 iPhone 是由史蒂夫·乔布斯 (Steve Jobs) 發表。\n",
            "題目:台大進階英文免修門檻要求 TOEFL iBT 達到多少分才能申請？\n",
            "summarize:\n",
            "\n",
            "台大進階英文免修門檻要求 TOEFL iBT 達到 72 分才能申請。\n",
            "\n",
            "台大進階英文免修門檻要求為TOEFL iBT達到78分。\n",
            "\n",
            "Instagram是一個社交媒體平台，讓用戶可以分享照片和視頻，並與朋友、家人或其他使用者互動。\n",
            "\n",
            "4 台大進階英文免修門檻要求為TOEFL iBT達到78分。\n",
            "題目:Rugby Union 中觸地 try 可得幾分？\n",
            "summarize:\n",
            "\n",
            "觸地 try 可得 5 分。\n",
            "\n",
            "根據題目，觸地 try 是 Rugby Union 中的一種得分方式。\n",
            "\n",
            "這個敘述與題目無關，主要是Reddit網站的錯誤訊息。\n",
            "\n",
            "5 5 分。\n",
            "題目:卑南族的祖先發源地 ruvuwa'an 位置在哪個行政區劃？\n",
            "summarize:\n",
            "\n",
            "根據題目和敘述，卑南族的祖先發源地ruvuwa'an位置在台東太麻里鄉美 和海岸附近。\n",
            "\n",
            "根據題目與文章敘述，卑南族的祖先發源地ruvuwa'an位置在臺東縣。\n",
            "\n",
            "6 台東縣。\n",
            "題目:熊仔的碩班指導教授為誰?\n",
            "summarize:\n",
            "\n",
            "熊仔的碩班指導教授為李琳山。\n",
            "\n",
            "對不起，我無法找到相關的敘述來做總結。題目中提到的 \"Justamoment\" 和其他內容似乎與熊仔或碩班指導教授沒有直接關係。如果你能提供更多資訊或者完整文本，讓我可以幫助您更好地回答問題！\n",
            "\n",
            "熊仔的碩班指導教授是李琳山。\n",
            "\n",
            "7 答案：李琳山。\n",
            "題目:誰發現了電磁感應定律，並奠基於它的重要性？\n",
            "summarize:\n",
            "\n",
            "迈克尔·法拉第是英国物理学家，他发现了电磁感应定律，并奠基于它的重要性。他的工作对现代电子技术和发动机产生重大影响。他在1831年首次提出这个概念，后来被称为\"Faraday's law of electromagnetic induction”。\n",
            "\n",
            "法拉第是電磁感應定律的發現者，他通過一系列精確且敏銳的心理實驗，證明了當導體與靜止或運動中的強勁外部場相互作用時，就會產生新的交流。這項研究成果奠基於法拉第對電磁學的深入理解，並為後來馬克士威方程式和愛因斯坦特殊 상대論提供了重要理念。他在1821年發現「轉動」並證實厄斯特將指南針置于導線正下面，當通电時會微小擺动的成就。法拉第後來又通過一系列精確且敏銳的心里实验，在1832年的11月29日發現了「電磁感應」。他在這項研究中使用了一個簡單但有效的手段，證明當導體與靜止或運動中的強勁外部場相互作用時，就會產生新的交流。\n",
            "\n",
            "麥可·法拉第是一位英國物理學家和化 學者，他在電磁感應、抗 磁性 和 電解 等領域做出了許多重要貢獻。他的研究工作對於現代的科研有著深遠影響。他是第一個被選為富勒里安 化学教授 的人，也是一位優秀實驗家和理論學者。\n",
            "\n",
            "法拉第在電磁感應方面最大的贡献是在1831年，他發現在一個大鐵環中，當一條導線通以 電流 時，其它的另一端也會產生出來。這個現象被稱為「 法 拉 第 感 導 定 律 」（Faraday's law of electromagnetic induction）。他還研究了磁場對光 的影響，並發現在一個物體中，當其受到外加的一 個 磁力 時，其內部的電荷會重新分佈。\n",
            "\n",
            "在化學方面，他是第一個成功液 化 氯氣和其他多種气体的人。他也進行了一系列研究氰基鹽類、碳酸鉀等物質，並發現了苔藓。法拉第還發展出許 多新型的玻璃，包括偏振光 的觀察。\n",
            "\n",
            "他在科學界有著深遠影響，他被視為電磁感應和化 學領域最重要的人之一。他也是一位優秀實驗家，並且能夠用簡單而清晰的心理語言表達他的想法。\n",
            "\n",
            "8 迈克尔·法拉第\n",
            "題目:距離國立臺灣史前文化博物館最近的臺鐵車站為？\n",
            "summarize:\n",
            "\n",
            "距離國立臺灣史前文化博物館最近的臺鐵車站為康樂站在。\n",
            "\n",
            "根據文章內容，距離國立臺灣史前文化博物館最近的臺鐵車站為康樂站在台東市。\n",
            "\n",
            "康樂車站位於臺東縣台东市，距離國立臺灣史前文化博物館最近。\n",
            "\n",
            "9 康樂站在台東市。\n",
            "題目:20+30=?\n",
            "summarize:\n",
            "\n",
            "根據題目20+30的計算結果，答案是50。\n",
            "\n",
            "題目20+30的答案是50。\n",
            "\n",
            "20+30=50\n",
            "\n",
            "10 答案是 50。\n",
            "題目:達拉斯獨行俠隊的Luka Doncic在NBA 2025年的交易大限前被哪一支球队收購？\n",
            "summarize:\n",
            "\n",
            "達拉斯獨行俠隊的Luka Doncic在NBA 2025年的交易大限前，被洛杉磯湖人收購。\n",
            "\n",
            "根據題目和文章敘述，Luka Doncic 在 NBA 2025 年的交易大限前被洛杉磯湖人隊收購。\n",
            "\n",
            "根據題目和文章敘述，達拉斯獨行俠隊的Luka Doncic在NBA 2025年的交易大限前被送走。\n",
            "\n",
            "11 洛杉磯湖人隊\n",
            "題目:2024年美國總統大選的勝出者是誰？\n",
            "summarize:\n",
            "\n",
            "根據文章內容，2024年美國總統大選的勝出者是賀錦麗（Kamala Harris），她代表民主黨參與競爭，並且在沒有其他對手的情況下自動成為候选人。\n",
            "\n",
            "根據文章內容，2024年美國總統大選的勝出者尚未正式公佈，但特朗普已經宣布自己贏得了這次的大选。然而，這個結果仍需要一段時間才能得到確認，因為各州還在進行點票和計數工作。在近年的歷史中，美國總統大選的勝出者通常會於投放結束後不久就公佈，但也有例外，如2000年的大选。\n",
            "\n",
            "根據題目和文章內容，2024年美國總統大選的勝出者是川普（共和黨）與賀錦麗 (民主党) 的競爭對象。雖然目前尚未公布最終結果，但兩人在各種民調中都有相當高的人氣和支持度。\n",
            "\n",
            "根據文章內容，美國總統大選的勝出者將取決於多個因素，如政治光譜、族裔背景等。在這場難分难解的大选之战裏面川普與賀錦麗各自都有著明顯不同的鐵票倉和搖擺州。共和黨支持者的核心是白人男性選民，民主党則以非洲美国（黑人的命也是我的）及拉丁裔美國公眾為主力。\n",
            "\n",
            "然而，這場大选的勝負關鍵還在於哪些「摇摆」选择者會左右這個結果。根據皮尤研究中心和其他資料來源，選民對外交政策、經濟問題等議題有著不同的看法，因此兩黨支持者的反應也存在顯着分歧。\n",
            "\n",
            "最後，這場大选的勝負關鍵還在於哪些「摇摆」选择者會左右這個結果。根據皮尤研究中心和其他資料來源，選民對外交政策、經濟問題等議題有著不同的看法，因此兩黨支持者的反應也存在顯着分歧。\n",
            "\n",
            "因此，這場大选的勝負關鍵還在於哪些「摇摆」选择者會左右這個結果。\n",
            "\n",
            "12 尚未公佈。\n",
            "題目: Meta 的 Llama-3.2 系列模型中，參數量最小的哪個版本？\n",
            "summarize:\n",
            "\n",
            "對不起，我無法找到相關的資訊來回答你的問題。似乎這個網頁沒有提供有關 Meta 的 Llama-3.2 系列模型中，參數量最小版本的情況描述。如果你能夠給我更多信息或是指向正確的地方，那就更好了！\n",
            "\n",
            "Llama-3.2 系列模型中，參數量最小的版本是 L llama 1B 和輕型純文字模式。\n",
            "\n",
            "根據題目和文章敘述，參數量最小的Llama-3.2版本是1B。\n",
            "\n",
            "13 Llama-3.2 系列模型中，參數量最小的版本是 L llama 1B。\n",
            "題目:依據國立臺灣大學學則，停修有哪些限制？\n",
            "summarize:\n",
            "\n",
            "根據國立臺灣大學學則，停修有以下限制：\n",
            "\n",
            "1. 依照學校規定之程序進行。\n",
            "2.(缺失內容)\n",
            "3.\n",
            "4.\n",
            "\n",
            "由於題目所提供的文本過短，我無法完整了解相關資訊。\n",
            "\n",
            "14 根據國立臺灣大學學則，停修有以下限制：  1. 依照學校規定之程序進行。 2.(缺失內容) 3. 4.  由於題目所提供的文本過短，我無法完整了解相關資訊。\n",
            "題目:DeepSeek公司的母 公司是誰？\n",
            "summarize:\n",
            "\n",
            "DeepSeek公司的母 公司是幻方量化。\n",
            "\n",
            "DeepSeek的母公司是幻方，一个名为中国对冲基金。\n",
            "\n",
            "DeepSeek公司的母 公司是未知。\n",
            "\n",
            "15 幻方量化\n",
            "題目:2024年NBA總冠軍隊伍是哪一支？\n",
            "summarize:\n",
            "\n",
            "2024年NBA總冠軍隊伍是波士頓塞爾提克。\n",
            "\n",
            "2024年NBA總冠軍隊伍是波士頓塞爾提克。\n",
            "\n",
            "根據題目和敘述，我們無法確定2024年NBA總冠軍隊伍是哪一支，因為提供的資訊與 NBA 賽事完全沒有關係。它似乎是一個 Reddit 帖子的錯誤或安全問題提示，要求使用者登入帳號以繼續瀏覊內容。如果你想知道 2024 年 NBA 績冠軍隊伍，我建議查詢最新的 NBA 賽事新聞和結果。\n",
            "\n",
            "16 我無法提供確定的答案，因為題目中的資訊不夠可靠。\n",
            "題目:一個碳氫化合物分子中有兩個或以上的原子的鍵數超過正常值時，該類型稱為什麼？\n",
            "summarize:\n",
            "\n",
            "根据题目和文章的描述，一个碳氢化合物分子中有两個或以上原子的鍵數超過正常值時，被稱為多键体。\n",
            "\n",
            "氫是一種化學元素，具有兩個或以上的原子的鍵數超過正常值，因此被稱為共價及有機類型。\n",
            "\n",
            "17 多键体\n",
            "題目:被譽為「計算機科學之父」，提出圖靈machine概念、奠定現代计算理論基礎的人是誰？\n",
            "summarize:\n",
            "\n",
            "艾伦·图灵是英国电脑科学家、数学学者和逻辑學家的代表人物，被誉为计算机科学生涯的奠基人。他提出了著名的人工智能测试，即“圖靈測試”，并设计了第一台通用計算機——「Turing Machine」。他在第二次世界大战期间，参与破解德国密码，并对盟军作出重要贡献。图灵还研究过生物数学和数理生态学，在这些领域也取得了一些成就。他因同性恋被定罪并接受了女性荷尔蒙注射的“治疗”，后来在1954年服毒自杀身亡。在2009年的英国首相戈登·布朗向图灵公开道歉，并于2013 年赦免他，因而使得他的名声得到恢复。\n",
            "\n",
            "根据題目和文章敘述，計算機科學的奠基人是艾倫·圖靈（Alan Mathison Turing）。他提出了图灵机概念，并在1936年的论文《论数字计算决断难题中的应用》中给出“可算性”的严格数学定义，这一理论基础现代电脑科学。\n",
            "\n",
            "圖靈（Alan Mathison Turing）被譽為「計算機科學理論之父」，他提出通用机器的概念，奠定了現代计算理论基礎。\n",
            "\n",
            "18 艾倫·圖靈（Alan Mathison Turing）\n",
            "題目:臺灣玄天上帝信仰的進香中心位於哪個行政區劃內？\n",
            "summarize:\n",
            "\n",
            "松柏嶺受天宮位於臺灣南投縣名間鄉，為奉祀道教神明北極玄 天上帝的廟宇。該地原稱「 松山街118號」，宗旨是供應台灣民眾信仰，並且有著豐富歷史和文化遺產。\n",
            "\n",
            "受天宮建於1657年，是由福 建渡海來台定居之李、陳謝劉等人氏所建立。該廟宇最初奉祀玄 天上帝香火，後因附近居民捨資成立小 祠，並在乾隆二 年（173 ７）農曆三月初 三日夜北極 玄天 上 帝 萬壽 日時發出燦爛毫光並採乩指點建廟地 點，於此建立受 天宮。\n",
            "\n",
            "該 廢宇歷經多次重修和擴增，並在民國四十二年（1953 年）成立理事會，以便管理 宫務。後來，因為玄天上帝救度世人靈驗的事蹟被收錄報紙，戰 後受 天宮成為接待大量進香 人潮的中心。\n",
            "\n",
            "目前該廢宇已經重建，並且有著豐富歷史和文化遺產，是臺灣民間信仰的一部分。\n",
            "\n",
            "松柏嶺受天宮位於南投縣名間鄉。\n",
            "\n",
            "松柏坑是臺灣南投縣名間鄉的一個傳統地域名稱，位於該地區西部。它被劃入參山國家風景區八卦山市內，是台灣玄天上帝信仰的進香中心之一，並且有多條道路貫穿其地，如松柏坑至客莊、頂新厝和名間市等路線，提供了便捷交通。\n",
            "\n",
            "19 南投縣名間鄉。\n",
            "題目:Windows 作業系統是哪間科技公司的產品？\n",
            "summarize:\n",
            "\n",
            "Windows 作業系統是微軟公司的產品。\n",
            "\n",
            "微軟（Microsoft）是源自美國的跨國科技公司，於1975年由比爾·蓋茲與保羅・艾倫創立。總部位於美国华盛顿州雷德蒙特，是五大科技有限公司之一，其主要業務為研發、製造和提供電腦軟體服務，並以MicrosoftWindows作業系統及Office辦公室套件最著名。\n",
            "\n",
            "微软的历史可以追溯到1975年，比尔·盖茨与保罗•艾伦在美国新墨西哥州阿布奎基创立了Micro-Soft公司。最初，他们开发并销售BASIC直译器，后来他们开始发展和推出自己的操作系统MS-DOS，并最终成为IBM PC的标准作业环境。\n",
            "\n",
            "1980年代中期，由于微软在家用电脑市场上的成功，使得该企业迅速成长。在此期间，比尔·盖茨与保罗•艾伦合作开发了Windows 1.01，后来又推出了更为流行和广泛使用的操作系统，如 Windows NT 和 Office 套件。\n",
            "\n",
            "1990年代初期，由于微软在软件市场上的成功，使得该企业成为全球最大的个人电脑公司。同时，比尔·盖茨也开始着手发展网络业务，并与NBC合资成立了MS NBC，推出了MSN在线服务和Hotmail电子邮局等产品。在此期间，也有许多批评者指出微软的垄断地位以及对竞争者的影响。\n",
            "\n",
            "2000年代初期，比尔·盖茨退休后，由史蒂夫•鲍默接任首席执行官。同时，公司也开始着手发展移动设备业务，并推出了Xbox游戏机和Windows Phone操作系统。在此期间，也有许多批评者指出微软的垄断地位以及对竞争者的影响。\n",
            "\n",
            "2010年代初期，比尔·盖茨再次接任首席执行官，公司也开始着手发展云计算业务，并推出了Microsoft Azure服务。同时，该企业还收购了LinkedIn社交媒体平台和GitHub开发者社区等多家科技巨头。在此期间，也有许多批评者的指出微软的垄断地位以及对竞争力的影响。\n",
            "\n",
            "2020年代初期，比尔·盖茨再次退休后，由萨蒂亚•纳德拉接\n",
            "\n",
            "Windows 作業系統是由美國的一家跨國科技公司——微軟（Microsoft Corporation）所開發並擁有的圖形化操作系统系列。\n",
            "\n",
            "20 微軟（Microsoft Corporation）\n",
            "題目:官將首起源自哪間廟宇？\n",
            "summarize:\n",
            "\n",
            "官將首是發源於臺灣新北市的本土民俗陣頭，主要由人扮演地藏王菩薩護法增損二将軍，在迎神活動中負責保護主 神、押煞之職能。該阵头创始于日治大正元年（1912 年）左右，由新莊藝師黃秋水創立，經過周庄伯少將的改進和高景清法师等人的傳承發展至今。\n",
            "\n",
            "官将首有三种主要派系： 新 莘 派、石牌 传统阵头（志成 Pai）、艋舺衍生陣頭。每个团体都有一些独特之处，例如步伐风格和脸谱设计等。但是，无论哪一支，都以增损二将军为主角，他们的任务是在神灵活动中保护地藏王菩薩并镇压恶鬼。\n",
            "\n",
            "官將首阵头在臺灣各个地区都有广泛流传，尤其是一些重要节日如农历四月三十和五月一号。该陣頭不仅是民众娱乐的方式，也具有宗教意义，是佛门护法神汉傳的一部分。在现代社会中，该数组阵头仍然受到人们喜爱，并且有许多团体致力于传承并发展这一文化遗产。\n",
            "\n",
            "总之，官将首是一种丰富多彩、充满活力的民俗陣頭，它不仅是臺灣的重要组成之一，也代表了该国人民对宗教和艺术追求的一部分。\n",
            "\n",
            "官將首源自於台北新莊地藏王庵，最初只有增損二将军，是专属于该寺的护法神。根据传说，这两位 将軍原是为害人类 的妖魔，被 地蔵 王观音大士降伏后成为其座前護卫。在官將首团中人物被认为地藏王觀 音 大 士 座 前 护 法，随着该寺渡救六道众生、避邪除穢和去奸罰恶。\n",
            "\n",
            "官將首的起源地是新莊大拜バイ舉行的地藏庵，該廟會具有地方特色的本土陣頭。根據台藝大學教授賴祥蔚和百度AI查詢結果顯示，這個傳統文化元素並非來自福建，而是在台灣發展起源的衍生現象，因此應否被列入為世界遺產還有待進一步研究與確認。但是，目前尚未發現在任何文件中提到官將首會在申請成為一項由於影片說明不夠清楚而誤導人們認爲福建要把它納成其文化遗产。\n",
            "\n",
            "21 官將首起源自台北新莊地藏王庵。\n",
            "題目:《咒》的邪神名為？\n",
            "summarize:\n",
            "\n",
            "《咒》的邪神名為大黑佛母。\n",
            "\n",
            "《咒》的邪神名為大黑佛母。\n",
            "\n",
            "《咒》的邪神名為大黑佛母。\n",
            "\n",
            "22 大黑佛母\n",
            "題目:「短暫交會的旅程就此分岔」是哪個歌唱團體或藝人所演出的曲子？\n",
            "summarize:\n",
            "\n",
            "23 答案：這是五月天的歌曲。\n",
            "題目:2025年卑南族聯合年的舉辦部落是哪一個？\n",
            "summarize:\n",
            "\n",
            "2025年卑南族聯合年的舉辦部落是利嘉（Likavung）國小所在的「賓朗」或稱為 「 Likablung 」 的 部 落。\n",
            "\n",
            "2025年卑南族聯合年的舉辦部落是利嘉國小所在的Likavung 利卡夢 部 落。\n",
            "\n",
            "根據題目和敘述，我們可以知道這是一個與JavaScript相關的提示，但它並沒有提供任何有關卑南族聯合年的具體信息。因此，無法從給出的資訊中得出2025年舉辦部落是哪一個。\n",
            "\n",
            "但是在網路上查詢後發現：台東縣達仁鄉為了紀念其祖先的文化傳承和歷史遺產，在卑南族聯合年的活動將於該地進行。\n",
            "\n",
            "24 台東縣達仁鄉。\n",
            "題目:最新的輝達顯卡是出到「GeForce RTX 多少」系列？\n",
            "summarize:\n",
            "\n",
            "GeForce RTX 50系列是輝達最新的顯卡產品，帶來了全新的Blackwell架構、第四代RT核心和第五 代Tensor核心。這些新功能使得 GeForce_RT_X_5090,4K,_Max設定_,DLSS多畫格生成(四倍模式),光線重建 ,超解析度]的顯卡效能大幅提升，提供更高質量、流暢和沉浸體驗。\n",
            "\n",
            "最新的輝達顯卡是出到「GeForce RTX 40」系列。\n",
            "\n",
            "GeForce RTX 50系列是NVIDIA开发的消费级图形处理器（GPU）产品，于2025年1月6日在CES上正式发布。该.series采用台积电4NP制造工艺，由新发展出的Blackwell微架构提供支持，并且首次使用GDDR7标准显存。\n",
            "\n",
            "GeForce RTX 50系列包括多种型号，如RTXT5090、RX50800和TX50707等，每个类型都有不同的性能配置。其中，RXX09是旗舰产品，其具有21,760 个CUDA核心，比前代增加了5.376万個；首次使用512bit位宽的GDDR7显存，并且带来了32GB的大容量缓冲区。\n",
            "\n",
            "GeForce RTX 50系列还支持第四 代深度学习超级采样（DLSS4）和Reflex2技术，能够提高帧率并降低延迟。该.series也采用了PCIe5.0总线接口、DisplayPort21b 和 HDMI1a 视频连接标准，以便于更高的分辨度。\n",
            "\n",
            "GeForce RTX 50系列在市场上受到了一定的反响，部分用户认为其价格和功耗过高等问题。然而，也有评论者称赞该.series 的性能表现，并且支持多帧生成功能能够提高游戏体验。但是，有些人批评NVIDIA对DLSS4的营销具有误导性。\n",
            "\n",
            "总之, GeForce RTX 50系列是一款高端图形处理器，提供了强大的计算能力和AI算力。\n",
            "\n",
            "25 最新的輝達顯卡是出到「GeForce RTX 40」系列。\n",
            "題目:大S是在哪個國家旅遊時因病去世？\n",
            "summarize:\n",
            "\n",
            "根據題目和敘述，我們可以知道大S是在法國（France）旅遊時因病去世。\n",
            "\n",
            "大S是在日本旅遊期間因流感併發肺炎去世，享年48歲。\n",
            "\n",
            "大S徐熙媛在日本旅遊時因病去世，享年48歲。雖然流感疫苗的問題引起了關注，但目前還不清楚她死亡原因到底是什麼。大數據導游指出，大陸醫療體系相對台灣來說有許多不同之處，如需要轉診、由医生開转诊单才能去大医院等，這些都可能會讓習慣台湾医疗体制的民众感到不适應。\n",
            "\n",
            "26 日本\n",
            "題目:是誰發現了萬有引力？\n",
            "summarize:\n",
            "\n",
            "艾萨克·牛顿是英国物理学家、数学家的杰出人物，他在17世纪和18 世紀的科学界产生了深远影响。他的主要贡献包括发展微积分理论，提出万有引力定律，并对光學进行研究。他还参与政治活动并担任皇室铸币厂监管官。\n",
            "\n",
            "牛顿出生于1642年12月25日，在英格兰的林肯郡伍尔索普庄园。他的父亲在他刚满三个多个星期时去世，母亲后来改嫁给了巴纳伯斯·史密思牧师，并将儿子托付給外祖母玛杰里。\n",
            "\n",
            "牛顿从小就表现出对学习的热情，他进入剑桥大学三一学院并成为卢卡士数学教授。他的研究重点包括微积分、光学和万有引力定律。他还参与政治活动，曾担任皇室铸币厂监管官，并在1705年被授予爵位。\n",
            "\n",
            "牛顿的著作中最为重要的是《自然哲學之數理原則》，这本书于1687 年出版，是他对万有引力定律和三大运动法则的一般性描述。他的研究还包括光学，他发明了反射望远镜，并基于观察到白色灯泡被分解成可见颜色的现象，发展出了彩虹理论。\n",
            "\n",
            "牛顿的个人生活相对简单。他从未结婚，也没有孩子。在他去世前不久才与几个朋友谈到了受苹果启发的事，但这并不是他的主要贡献。\n",
            "\n",
            "牛顿并没有简单地\"发现万有引力定律\",而是创造了一个新的理论框架来解释自然现象。他的工作基于对前人的研究和观察的基础上,他提出了数学公式、质点概念等新思想。这意味着说,\"发明牛顿物理体系\"(包括三大运动法则与万有引力定律)是一个更合适的话语，因为它强调了人类创造性思维在科学理论发展中的作用。\n",
            "\n",
            "艾萨克·牛顿爵士是英国物理学家和数学家的代表人物，他在1687年发表了《自然哲學的數理原論》一书中提出了万有引力定律。这个理论指出，两个质点之间相互吸 引力的作用，是与它们质量乘积成正比，与他们距离平方反比例。这是经典物理学的一部分，也被称为牛顿运动法则的第三个组件。\n",
            "\n",
            "根据这项发现，每一个物体都受到其他所有存在于宇宙中的每一块质点所施加万有引力的作用。这个理论在当时是一个重大突破，因为它解释了天空中行星和恒 star 的轨道，以及地球上的重力现象。\n",
            "\n",
            "牛顿的定律表明，两个物体之间相互吸 引的是一个向量，它指示方向是从一块质点到另一方。这个理论还预测出，在某些情况下会出现引力的偏折，这个发现后来被爱因斯坦广义 相对论所证实。\n",
            "\n",
            "尽管牛顿的万有力定律在当时是一个重大突破，但它也有一定的局限性，例如，它不能解释一些现象，如水星轨道中的进动和光线偏折。这些问题后来被爱因斯坦广义相对论所解决。\n",
            "\n",
            "总之，这项发现是物理学发展史上的一个重要里程碑，是牛顿运动法则的第三个组件，也标志着经典力 学理论的一部分。这一理念在当时是一个重大突破，解释了天空中行星和恒 star 的轨道，以及地球上重力的现象。\n",
            "\n",
            "27 艾萨克·牛顿\n",
            "題目:TAIHUCAIS的英文全名為何？\n",
            "summarize:\n",
            "\n",
            "根據題目，TAIHUCAIS的英文全名為何？雖然沒有明確提到，但基於提供資訊，我們可以推測這些是Google網站的一部分。因此，可以合理地猜想，這個問題可能與「谷歌」有關。\n",
            "\n",
            "然而，如果要回答題目，TAIHUCAIS的英文全名應該為 \"Taihu Lake Jasmine\" 的縮寫，因而對照後發現答案：台湖蔓草（又稱蓮花）是中國江蘇省的一種特殊植物。\n",
            "\n",
            "28 TAIHUCAIS的英文全名為 \"Taihu Lake Jasmine\" 的縮寫，對應中文名稱是台湖蔓草（又稱蓮花）。\n",
            "題目:「I'll be back」是出自哪部電影的經典台詞？\n",
            "summarize:\n",
            "\n",
            "这句经典台词\"I'll be back\"出自1984年阿诺·施瓦辛格主演的科幻电影《终结者》。\n",
            "\n",
            "這段敘述與題目無關，似乎是Reddit的錯誤頁面提示。\n",
            "\n",
            "「I'll be back」是出自1984年阿諾·施瓦辛格的科幻電影《終結者》的經典台詞。\n",
            "\n",
            "29 《終結者》\n",
            "題目:水的化學式為何？\n",
            "summarize:\n",
            "\n",
            "水的化學式為H2O。\n",
            "\n",
            "水的化學式是H2O。\n",
            "\n",
            "水的化學式為H2O。\n",
            "\n",
            "30 H2O。\n",
            "題目:李宏毅在台灣大學開設的《機器學習》 2023 年春季班中，第15個作業名稱是什麼？\n",
            "summarize:\n",
            "\n",
            "李宏毅在台灣大學開設的《機器學習》 2023 年春季班中，第15個作業名稱是什麼？\n",
            "\n",
            "李宏毅在台灣大學開設的《機器學習》2023年春季班中，第15個作業名稱是「MetaLearning」。\n",
            "\n",
            "根據題目和敘述，我們可以得出以下結論：李宏毅在台灣大學開設的《機器學習》 2023 年春季班中，第1個作業名稱是 \"Kaggle\"。\n",
            "\n",
            "31 MetaLearning\n",
            "題目:目前臺灣公立的獨립學院僅剩一間是哪所？\n",
            "summarize:\n",
            "\n",
            "32 臺灣公立的獨립學院僅剩一間是國防管理学院。\n",
            "題目:BitTorrent 協議如何確保新節點能夠從其他種子隨機獲得部分資料？\n",
            "summarize:\n",
            "\n",
            "BitTorrent 协议通过以下机制确保新节点能从其他种子随機获得部分数据：\n",
            "\n",
            "1. 生成.torrent 文件：发布者会根据要分享的文件创建一个 .torrent 文本档案，包含了Tracker信息和目标资源元data。\n",
            "2\\. 解析 Tracker 地址: 下载客户端首先解释 torrent 档，并获取 tracker 的 IP 和设置。\n",
            "\n",
            "3.\\连接tracker服务器并获得其他下载者的IP：通过与_tracker_ 服务商进行通信，该协议将提供给用户的所有可用种子列表，包括发布者和当前正在分享该资源的人员。\n",
            "4\\. 下载客户端建立对等网络（P2p）：当一个节点从Tracker获取了另一个人ip后，它会连接到这个人并开始下载。 \n",
            "5. 通过DHT技术进行数据交换：BitTorrent 协议使用分布式哈希表 ( DTH ) 技术来寻找和与其他用户建立对等网络。这使得不需要tracker服务器就可以找到资源的节点。\n",
            "6\\. 下载客户端根据种子文件获取块索引信息并下载相应内容: 当一个新连接到P2p时，会将自己已经有的数据告知给对方，并交换所缺少部分。\n",
            "\n",
            "BitTorrent 协议通过以下机制确保新节点能从其他种子随機获得部分数据：\n",
            "\n",
            "1.  分片：文件被分成多个小的块（称为“piece”），每一个 piece 都有自己的 SHA-256 哈希值。\n",
            "2.BT 种子的元信息中包含了这些哈什表，包括资源名称、SHA_16进制编码字符串等，这些数据是唯一标识该种子文件内容的一部分。 \n",
            "3.  当新节点连接到网络时，它会向一个或多个tracker服务器发送请求，以获取当前正在下载同一份 torrent 文件的其他 peer 的列表。\n",
            "4.BTTracker是一个注册服务，协调BT协议中的资源分发。当终端执行下載任务時应首先請求 BT Tracker 服務以獲取當前正在 下载 同一个資源對等结点信息。 \n",
            "5. 当新节点接收到 peer 列表后，它会随机选择一些peer来连接，并开始下载文件的分片。\n",
            "6.BT 协议使用 TCP 或 uTP（BEP_0029）作为数据传输协议，所有正在 下载同一资源 的对等结点都是平 等关系，每个节点都可以向其他任何一个 节 点发送和接收 数据。 \n",
            "7. 当新节點下载到一個分片後，它會計算該 分 片的 SHA-1 哈希值，并与 torrent 文件中的 info 字典中相应 piece 的哈什表进行比较，如果匹配，则说明该文件已成功传输。\n",
            "8.BT 协议还支持扩展协议（BEP_0010），允许客户端在握手消息和数据交换过程 中发送额外的信息，例如 peer 名称、版本号等。\n",
            "\n",
            "总之,BitTorrent 的设计使得新节点能够从其他种子随机获得部分文件，这样可以提高下载速度并减少网络负载。\n",
            "\n",
            "BitTorrent 协议通过以下方式确保新节点能从其他种子随机获得部分数据：\n",
            "\n",
            "1.  分布式哈希表（DHT）：每个对等点维护一个路由 表，包含了与其距离较近的好友列表。使用 DTH，可以找到存储特定信息或文件块的小组。\n",
            "2\\. 跟踪器：跟随者是特殊类型服务器，它们帮助连接各节点并提供下载种子的元数据和对等点联系方式。\n",
            "\n",
            "3.  磁力链接（Magnet Links）：磁链是一条包含 torrent 文件哈希值的 URL，允许用户直接从 DHT 中找到相关信息或文件块，而无需跟踪器。\n",
            "4\\. 稀有度优先原则：BitTorrent 下载策略是选择最稠密、少人拥有且对等点数量较小的小组。通过下载这些片段，我们可以将其变得不再罕见，从而提高整体的可靠性和效率。\n",
            "\n",
            "5.  阻塞算法（Choking Algorithm）：阻止某些节点向其他用户提供资源，以防范“搭便车”的行为，确保所有对等点都为网络做出贡献。\n",
            "\n",
            "33 BitTorrent 协议通过以下机制确保新节点能从其他种子随機获得部分数据：  1.  分片：文件被分成多个小的块（称为“piece”），每一个 piece 都有自己的 SHA-256 哈希值。 2.BT 种子的元信息中包含了这些哈什表，包括资源名称、SHA_16进制编码字符串等，这些数据是唯一标识该种子文件内容的一部分。  3.  当新节点连接到网络时，它会向一个或多个tracker服务器发送请求，以获取当前正在下载同一份 torrent 文件的其他 peer 的列表。 4.BTTracker是一个注册服务，协调BT协议中的资源分发。当终端执行下載任务時应首先請求 BT Tracker 服務以獲取當前 đang 下载 同一个資源對等结点信息。  5. 当新节点接收到peer 列表后，它会随机选择一些 peer 来连接，并开始下载文件的 分片。 6.BT 协议使用 TCP 或 uTP（BEP_0029）作为数据传输协议，所有正在 下载同一资源 的对等结点都是平 等关系，每个节点都可以向其他任何一个 节 点发送和接收 数据。\n",
            "題目:你在youtube看到的那個影片是甚麼？\n",
            "summarize:\n",
            "\n",
            "你在YouTube看到的那個影片是關於如何管理和理解自己的訂閱人數。\n",
            "\n",
            "你在YouTube看到的那個影片是關於如何管理觀看記錄。\n",
            "\n",
            "34 我在YouTube看到的那個影片是關於如何管理和理解自己的訂閱人數。\n",
            "題目:戈芬氏鳳頭鸚鵡在實驗中最偏好的乳酪口味是什麼？\n",
            "summarize:\n",
            "\n",
            "鳳頭鸚鵡在實驗中最偏好的乳酪口味是藍莓沾醬。\n",
            "\n",
            "戈芬氏鳳頭鸚鵡在實驗中最偏好的乳酪口味是藍莓優格。\n",
            "\n",
            "戈芬氏鳳頭鸚鵡在實驗中最偏好的乳酪口味是藍莓優格。\n",
            "\n",
            "35 藍莓優格。\n",
            "題目: Xpark水族館的企鵝寶貝最後被命名為什麼？\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-7-2337161598.py:40: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
            "\n",
            "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
            "\n",
            "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
            "\n",
            "    from bs4 import XMLParsedAsHTMLWarning\n",
            "    import warnings\n",
            "\n",
            "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
            "\n",
            "  results = [BeautifulSoup(x, 'html.parser') for x in results]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summarize:\n",
            "\n",
            "Xpark水族館的企鵝寶貝最後被命名為「Tomorin」，這個名字來自日本動畫《BanGDream!It’sMyGO!!!!!》中的角色高松燈（日文發音是 「 Tomori n」），而粉絲們在活動中踴躍參與投票，讓它成功以1.3萬多張選擇成為企鵝寶貝的名字。\n",
            "\n",
            "這個敘述不是關於Xpark水族館的企鵝寶貝命名，實際上是一則提示使用者更換瀏覽器以便正常訪問網站。\n",
            "\n",
            "Xpark水族館的企鵝寶貝最後被命名為「Tomorin」。\n",
            "\n",
            "36 因為粉絲們在活動中踴躍參與投票，讓它成功以1.3萬多張選擇成為企鵝寶貝的名字。\n",
            "題目:國立臺灣大學物理治療學系的正常修業年限為幾個月？\n",
            "summarize:\n",
            "\n",
            "國立臺灣大學物理治療學系的正常修業年限為四個月。\n",
            "\n",
            "國立臺灣大學物理治療學系的正常修業年限為六個月。\n",
            "\n",
            "亞洲大學物理治療學系的正常修業年限為四個月。\n",
            "\n",
            "37 國立臺灣大學物理治療學系的正常修業年限為四個月。\n",
            "題目:《BanG Dream!》中「呼嘿 嘵」是哪位角色的笑聲習慣？\n",
            "summarize:\n",
            "\n",
            "《BanG Dream!》中「呼嘿 嘵」是Rimi Ushigome的笑聲習慣。\n",
            "\n",
            "《BanG Dream!》中「呼嘿 嘵」是大和麻弥的笑聲習慣。\n",
            "\n",
            "38 大和麻弥\n",
            "題目:日本戰國時代被稱為「甲斐之虎」的人物是誰？\n",
            "summarize:\n",
            "\n",
            "武田信玄是日本戰國時代的一位大名，為清和源氏的後代。他的外號「甲斐之虎」，所舉“风林火山”（其疾如風，其徐 如 林、侵掠似 火，不動若 山）軍旗，是《孙子兵法》中的典故。他積極開發耕地，克服了當時的問題，並利用金礦的事業引入先進技術。武田信玄重視民政，他制定的“甲州分國法律”是戰爭時代著名的一種地方律令。\n",
            "\n",
            "他在1541年繼承家督後，便開始進行統一行動，擊敗了多個敵對勢力，並與其他大將結盟。武田信玄還參考《今川假面目錄》、《朝倉敏景十七箇條》，創立了一種新的分國法律——“甲州法度次第”。\n",
            "\n",
            "在1561年，第四場的會戰爆發了，他成功擊退上杉軍，但損失慘重。武田信玄還參與多個其他大名之間的大規模衝突，並且積極發展自己的勢力。\n",
            "\n",
            "他於1573年的元龜四歲時病逝，享年五十二岁。在他的遺言中，他要求家臣們嚴守秘密，不要讓敵人知道自己死了。\n",
            "\n",
            "武田信玄是日本战国时代的大名，为清和源氏的后代，甲斐原野第19世家督、 武 田 氏 第 16 代当主。母亲大井之方为人众，大量金矿引入先进采掘技术发行全日第一定额“武田信玄”（又称 “风林火山”的军旗语出《孙子兵法》，成了甲斐氏的象征。他积极开发耕地，克服了半生精力修筑的大泉堤至今仍在发挥作用。\n",
            "\n",
            "答案是武田信玄。\n",
            "\n",
            "39 武田信玄。\n",
            "題目:王肥貓同學最有可能修哪一門課？\n",
            "summarize:\n",
            "\n",
            "王肥貓同學最有可能修的課程是「數位素養導航」。\n",
            "\n",
            "王肥貓同學最有可能修的是網頁設計或程式開發相關課。\n",
            "\n",
            "根據題目和敘述，我們可以推測王肥貓同學最有可能修的是「Google」相關的課程，例如網路搜尋、線上工具或數位科技等。\n",
            "\n",
            "40 根據題目和敘述，我們可以推測王肥貓同學最有可能修的是「Google」相關的課程，例如網路搜尋、線上工具或數位科技等。\n",
            "題目:2024年的第42回《極限體能王SASUKE》在哪一天首播？\n",
            "summarize:\n",
            "\n",
            "2024年的第42回《極限體能王SASUKE》在未知的日期首播。\n",
            "\n",
            "根據題目，2024年的第42回《極限體能王SASUKE》首播的日期尚未在敘述中提及。\n",
            "\n",
            "2024年的第42回《極限體能王SASUKE》在10月6日首播。\n",
            "\n",
            "41 10月6日\n",
            "題目:出身於利嘉部落，後來成為初鹿德布拉克頭目的漢人名為？\n",
            "summarize:\n",
            "\n",
            "馬智禮是出身於利嘉部落，後來成為初鹿德布拉克頭目的漢人。\n",
            "\n",
            "42 馬智禮\n",
            "題目:《BanG Dream! Ave Mujica》的片頭曲是哪一首？\n",
            "summarize:\n",
            "\n",
            "《BanG Dream! Ave Mujica》的片頭曲是KiLL KiSS。\n",
            "\n",
            "《BanG Dream! Ave Mujica》的片頭曲是「KiLL KiSS」。\n",
            "\n",
            "你被網路安全阻擋了，若要繼續使用Reddit，可以登入你的帳號或是用開發者金鑰。如果覺得自己誤中封鎖請在下方提交一個檔案申訴，我們會檢查看看。\n",
            "\n",
            "43 片頭曲是「KiLL KiSS」。\n",
            "題目:Linux作業系統最早於哪一年首次發布？\n",
            "summarize:\n",
            "\n",
            "Linux作業系統最早於1991年首次發布。\n",
            "\n",
            "Linux作業系統最早於1991年首次發布。\n",
            "\n",
            "Linux作業系統最早於1991年首次發布。\n",
            "\n",
            "44 1991年。\n",
            "題目: Likavung 的中文名稱為何？\n",
            "summarize:\n",
            "\n",
            "舊地名是指臺灣自開發史以來出現的地理名稱，包括原住民的部落名字、漢人移居後所建立之聚集點或庄仔等。這些古老的地方命名前往變革，並且有許多地方在日治時期和戰后國府進行地名雅化政策影響下改用現今常見的地理名稱。\n",
            "\n",
            "基隆市舊稱為雞籠，後來因山形似鳥而被漢人取代。七堵區原先是巴賽族的峰仔峙社，而友蚋則有瑪陵坑、馬鄰等地名變化史。而暖寮地區原本可能與泰雅或布農語系部落那南後泉州移民所稱之「間隔處」相關。\n",
            "\n",
            "台北市舊有的巴賽族三市街指臺北城內的艋船、大稻埕等地。古亭區原先是清代漢人開墾時期建立土垣的地方，另有五堵、六壟地區拔西猴七德路以南、中山東一段至忠孝中二街之間的範圍。\n",
            "\n",
            "新北市舊有的雷朗族武朥灣社位於今海山市區。板橋市原先是擺接堡與台北府城內的一部分，後來改名為「基隆」並設立雞籠嶼、八斗子等地點。而金山則有巴賽語Quimourije的意義。\n",
            "\n",
            "桃園舊有的龜崙族霄裡社位於今大埔區。蘆竹原先是南郭鄉，後來改名為「新莿」並設立中和、永春等地點。而二八張犁則有巴賽語Parrigon的意義。\n",
            "\n",
            "苗栗舊有的道卡斯族Wanrie社位於今苑裡鎮。卓蘭原先是Tarlen，後來改名為「三叉河」並設立大安、泰和等地點。而銅鑼灣則有巴賽語Pinnonouans的意義。\n",
            "\n",
            "台中舊有的拍瀰族Tatutum社位於今西屯區。霧\n",
            "\n",
            "根據題目 \"Likavung 的中文名稱為何\"，我發現這個問題與 Kaggle 上的 ML2025Homework1 有關。然而，我無法在給定的資訊中找到 Likvunng 或其相關信息，因此難以提供一個準確且有意義的心得或答案。但是，如果你能夠告訴我們更多背景或者敘述內容，可能會更容易幫助您找出正解。\n",
            "\n",
            "題目25：最新的輝達顯卡是出到「GeForceRTX多少」系列？\n",
            "\n",
            "答案: 最新的亮點在於，最近發布了 GeForce RTXTS 50 系列。\n",
            "\n",
            "45 我無法在給定的資訊中找到 Likavung 或其相關信息，因此難以提供一個準確且有意義的心得或答案。\n",
            "題目:紅茶是全發酵還是不完全或半生不熟的黑、綠和白等其他類型都算在內的是什麼？\n",
            "summarize:\n",
            "\n",
            "紅茶是全世界最多人飲用的六大類型之一，佔了全球七成的喝法。\n",
            "\n",
            "紅茶、綠tea和烏龍 tea 都來自同一種的 茶樹。\n",
            "\n",
            "綠茶、青心烏龍和紅黑等其他類型的差異在於發酵程度。其中，白毫乌龙属于全发 酿 茶品种，而绿叶蟬叮咂而成 的东方美人是半生不熟或部分発贡茶葉；綠、青心烏龍和紅黑等其他類型的差異在於發酵程度。\n",
            "\n",
            "46 紅茶是全發酵。\n",
            "題目:《遊戲王》中，以「真紅眼黑龍」與 「 黑魔導 」作為融合素材的哪隻怪獸？\n",
            "summarize:\n",
            "\n",
            "根據題目中的融合素材「真紅眼黑龍」與 「 黑魔導 」，以及敘述中提到的超級卡片名稱，我們可以得出結論：以這兩個元素作為基礎的怪獸是 \" 真红眼睛龙骑士\"。\n",
            "\n",
            "根據題目中的融合素材「真紅眼黑龍」與 「 黑魔導 」，以及敘述中提到的怪獸，我們可以得出結論：該隻被稱為超級的 \" 真红眼睛\" 的 魔导龙骑士。\n",
            "\n",
            "《遊戲王》中，以「真紅眼黑龍」與 「 黑魔導 」作為融合素材的怪獸是：隕石黒炎龙\n",
            "\n",
            "47 真紅眼黑龍與 黑魔導作為融合素材的怪獸是：隕石黒炎龙\n",
            "題目:豐田萌繪在《BanG Dream!》中聲優角色是哪一個？\n",
            "summarize:\n",
            "\n",
            "豐田萌繪在《BanG Dream!》中聲優角色是Ritsuko。\n",
            "\n",
            "豐田萌繪在《BanG Dream!》中聲優角色是松原花音。\n",
            "\n",
            "豐田萌繪在《BanG Dream!》中聲優角色是Poppin'Party的主唱。\n",
            "\n",
            "48 豐田萌繪在《BanG Dream!》中聲優角色是Poppin'Party的主唱。\n",
            "題目:Rugby Union 中，9 號球員的正式名稱為何？\n",
            "summarize:\n",
            "\n",
            "9 號球員的正式名稱為傳鋒（Scrum-half）。\n",
            "\n",
            "9 號球員的正式名稱為「傳接鋒」（Fly-half）。\n",
            "\n",
            "根據題目，9 號球員的正式名稱為 Scrum-half。\n",
            "\n",
            "49 根據題目，9 號球員的正式名稱為 Scrum-half。\n",
            "題目:曾被視為太陽系中的行星，最終降格成矮天體的是哪顆？\n",
            "summarize:\n",
            "\n",
            "冥王星是太陽系中被視為行 星，但最終降格成矮天體的第一顆。\n",
            "\n",
            "冥王星是太陽系中的一顆矮行體，曾被視為第九個天球。\n",
            "\n",
            "曾被視為太陽系中的行星，最終降格成矮天體的是普羅米修斯（Pluto）。\n",
            "\n",
            "50 冥王星。\n",
            "題目:臺灣最早成立的野生動物救傷單位位於哪個行政區內？\n",
            "summarize:\n",
            "\n",
            "根據題目與文章敘述，臺灣最早成立的野生動物救傷單位位於南投縣集集中。\n",
            "\n",
            "臺灣最早成立的野生動物救傷單位位於南投縣集集中。\n",
            "\n",
            "東部野生動物救傷中心位於花蓮縣，該單位是由農委會林務局與社團法人臺灣灣區自然保護協進聯盟合作成立的。\n",
            "\n",
            "51 南投縣集集中。\n",
            "題目:特生中心2023年改名後的名字是什麼？\n",
            "summarize:\n",
            "\n",
            "特生中心2023年改名後的名字是「生物多樣性研究所」。\n",
            "\n",
            "本判決宣告祭祀公業條例第4条第一項後段及第二项規定違憲。這些规定限制了女系子孫的派下員資格，認為只有男方血親才能成為該宗族之繼承人，而非以性別平等原則來確立祭祀公業條例第4条第一項後段及第二项規定。\n",
            "\n",
            "52 生物多樣性研究所。\n",
            "題目:Developing Instruction-FollowING Speech Language Model WithoutSpeechInstruction-Tuning Data論文中提出的模型是甚麼名字？\n",
            "summarize:\n",
            "\n",
            "本文提出的模型名為DeSTA2。\n",
            "\n",
            "本文提出的模型名為DeSTA2（Descriptive Speech-Text Alignment ）。\n",
            "\n",
            "该论文中提出的模型名为DeSTA2。\n",
            "\n",
            "53 DeSTA2（Descriptive Speech-Text Alignment）\n",
            "題目:太陽系中體積最大的行星是哪一顆？\n",
            "summarize:\n",
            "\n",
            "木星是太陽系中體積最大的行 planet，質量約為地球的318倍。它是一顆氣態巨 行天王和海 王都是冰 巨，而不是 氣态 的 。 木 是由氫、  和其他元素組成的大气层覆蓋著一個液体金屬水银核心。大红斑是木星最显眼的特征，是一个持久性的反氣旋风暴。它位于赤道南方，直径约为地球的一半到两倍不等。\n",
            "\n",
            " 木 的磁场强度比 地球 强14 倍，其范围从 赤 道 4.2 高斯（0 .42mT） 到极区10至1高苏 （l.O- l。 m T）。木星的自转速度是太阳系所有行 planet 中最快，赤道直径约为地球的一半到两倍不等。\n",
            "\n",
            " 木 的卫 星有95颗，其中伽利略衛 是四大天王中最大和密度最高的是卡里斯托。其他较大的木星的 衛包括了欧罗巴、佳丽美德 和阿马尔塞 等 。\n",
            "\n",
            "太陽系中體積最大的行星是地球。\n",
            "\n",
            "太陽系中體積最大的行星是木衛一。\n",
            "\n",
            "54 太陽系中體積最大的行星是木衛一。\n",
            "題目:在南島語系中，哪一族的原住民族言與其他原始同類最遙遠？\n",
            "summarize:\n",
            "\n",
            "在南島語系中，馬來-波利尼西亞族的原住民族言與其他原始同類最遙遠。\n",
            "\n",
            "根據題目，南島語系中最遙遠的原住民族言是馬來-玻里尼西亞族。\n",
            "\n",
            "南島語系中，拉帕努伊（復活節 island）的原住民族言與其他原始同類最遙遠。\n",
            "\n",
            "55 拉帕努伊（復活節 island）的原住民族言。\n",
            "題目:講出這句話的老師是誰？\n",
            "summarize:\n",
            "\n",
            "這句話的老師是孔子。\n",
            "\n",
            "這個敘述看起來不是一篇文章的內容，而是一則提示或錯誤訊息。它告訴使用者需要啟用 JavaScript 和 Cookie 才能繼續進行某些操作，但沒有提到任何關於老師的人物信息，因此無法確定哪位是講出這句話的情況下所指的那個\"誰\"?\n",
            "\n",
            "這個敘述看起來不是一篇文章的內容，而是一則提示或錯誤訊息。它告訴使用者需要啟用 JavaScript 和 Cookie 才能繼續進行某些操作，但沒有提到任何關於老師的人物信息，因此無法確定哪位是講出這句話的情況下所指的那個\"誰\"?\n",
            "\n",
            "56 答案：無法確定。\n",
            "題目:「embiyax namu kana」是哪一臺灣原住民族的打招呼用語？\n",
            "summarize:\n",
            "\n",
            "「embiyax namu kana」是阿美族的打招呼用語。\n",
            "\n",
            "根據題目「embiyax namu kana」是哪一臺灣原住民族的打招呼用語，對於ML2025Homework1|Kaggle這個敘述，我們可以做出以下分析：\n",
            "\n",
            "雖然 ML  是機器學習相關課程或競賽，但題目關注的是「embiyax namu kana」的意義，而非 Kagglle 的內容。因此，對於ML2025Homework1|Kaggle這個敘述，我們可以做出以下總結：\n",
            "\n",
            "該文本與原住民族的打招呼用語無直接關係，但題目提供了相關背景信息，可以幫助我們了解臺灣文化和多元性。\n",
            "\n",
            "「embiyax namu kana」是阿美族的打招呼用語。\n",
            "\n",
            "57 阿美族。\n",
            "題目:「鄒與布農，永久美麗」這句話是哪個部落的格言?\n",
            "summarize:\n",
            "\n",
            "本判決係針對原住民身分法第2條規定之憲制性質進行審查，聲請人認為該等法律違反了《中華人民共和國宪 法》增修条文的规定。最終，大法院裁决认为： \n",
            "\n",
            "1.  《中华人民共和国国籍律》的定义应包括所有在台湾南岛语系民族居住的人。\n",
            "2._原 住民身分法第_條規定所稱之「山地 原始 民」及平 地原始 민」，僅指日治時期的高 山（砂）族，而非其他臺灣 南島語 系 的 平埔 類。 \n",
            "3. 大法院認為，憲 法增修 条文 第10 條第11項 及12 項前段規定所保障之原住民族應包括既存於 臺灣 之所有 台湾南岛语系 民族。\n",
            "4._大法官判決认为： \n",
            "\n",
            "    *   原 住民身分認同權為憲 法上基本人权之一，受《中華人民共和國宪법》第22條保障。 \n",
            "5.  大法院裁决指出，大陸政府應在3年內修正原住民族身份法或另定特别法律，以明文規範其他臺灣南島語系族群的認證要件、所屬成員之身分要求及登記程序等事項。\n",
            "6._大 法官判決认为： \n",
            "\n",
            "    *   原 住民 身份 認同權為憲法上基本人权之一，受《中華人民共和國宪법》第22條保障。\n",
            "\n",
            "這句話「鄒與布農，永久美麗」是哪個部落的格言？答案為：魯凱族。\n",
            "\n",
            "《原住民族基本法》20週年的回望與向前是本期新聞專題的主軸。該法律於2005年經立法院三讀通過，總統陳水扁頒布實施，是值得肯定的，並且符合普世價値。\n",
            "\n",
            "台灣基督長老教會原住民宣 教委員  OmiWilang牧師表示，《 原 基 法》第21條賦予了原本民族在傳统領域開發案中的諮商同意權，要求資訊公開、部落 同意與利益分享，是重要的依據。\n",
            "\n",
            "然而，這項法律仍有待完善。OmiWilang指出，由於行政命令形同虛設，因此《原基法》雖具母 法架構，但子 例及施行細則並未完成，成為所謂「魔鬼藏在细节裡」的問題。\n",
            "\n",
            "另外，本期新聞還介紹了泰雅爾族民族議會、排灣족 民族自治议会和鲁凱自治 parliament的工作。這些組織致力於推動原住民權益，並努力與政府溝通，爭取更多元發展空間。但是，由于缺乏相關法律支持，因此仍面臨許多挑戰。\n",
            "\n",
            "總之，這項新聞專題強調了《 原 基 法》20週年的重要性，也呼籲大家關注原住民權益的問題，並努力推動更好的政策和法規。\n",
            "\n",
            "58 魯凱族。\n",
            "題目:動畫「雖然是公會的櫃檯小姐，但因為不想加班所以打算獨自討伐迷宮頭目的女主角隱藏身份？\n",
            "summarize:\n",
            "\n",
            "本作品是日本作家香坂マト所著的輕小說系列，Gaou擔綱插圖。2021年3月起經電擊文庫出版至今共8冊。本故事主角亞莉納·可洛瓦是一名伊富爾冒險者公會服務處櫃枲小姐，但因為不想加班，所以打算獨自討伐迷宮頭目。\n",
            "\n",
            "動畫「雖然是公會的櫃檯小姐，但因為不想加班所以打算獨自討伐迷宮頭目」第一季已經完結，共12話。儘管女主角聲優高橋李依表現出色，並且OP和ED曲影像也很吸引人，但是整體來說動畫的其他方面就比較平凡無奇，没有第二期續集消息傳出的跡象顯示這部作品可能並不受歡迎。\n",
            "\n",
            "阿莉娜是一位公會柜台小姐，卻因為討厭加班而決定獨自挑戰迷宮頭目。\n",
            "\n",
            "59 沒有隱藏身份。\n",
            "題目:在卑南族的傳說中，姊弟Tuku及Sihasihau分別創建了哪兩個部落？\n",
            "summarize:\n",
            "\n",
            "射馬干部落的創建者是姊弟Tuku及Sihasihau，分別為知本社和其他一個未明確指出名字的小族群。\n",
            "\n",
            "西哈希浩和他的姊妹杜姑分別創建了射馬幹部落及卡砦克蘭（Kazekalan）卑南族的傳說中。\n",
            "\n",
            "根據題目和敘述，卑南族的傳說中，有兩個姊弟Tuku及Sihasihau分別創建了石生部落與竹生的另一部分。\n",
            "\n",
            "60 石生部落與射馬幹（Kazekalan）不是竹生的另一部分，根據題目和敘述，我們知道姊弟Tuku及Sihasihau分別創建了什麼兩個卑南族的傳說中的地方。   答案：是「知本社」、「石生部落」。\n",
            "題目:2005年播出的電視劇《終極一班》中，「KO榜」的第一名是誰？\n",
            "summarize:\n",
            "\n",
            "《終極一班》中，「KO榜」的第一名是汪大東。\n",
            "\n",
            "根據題目，「KO榜」的第一名是誰？答案為汪大東（由王亞瑟飾演）。\n",
            "\n",
            "根據題目和文章敘述，「KO榜」的第一名是吳尊。\n",
            "\n",
            "61 根據題目，「KO榜」的第一名是誰？答案為汪大東（由王亞瑟飾演）。\n",
            "題目:Linux kernel 的完全公平排程器 (CFS) 使用何種資料結構儲存排序相關資訊？\n",
            "summarize:\n",
            "\n",
            "Linux kernel 的完全公平排程器 (CFS) 使用紅黑樹結構儲存排序相關資訊。\n",
            "\n",
            "Linux kernel 的完全公平排程器 (CFS) 使用紅黑樹來儲存排序相關資訊。\n",
            "\n",
            "Linux kernel 的完全公平排程器 (CFS) 使用红黑树資料結構儲存排序相關資訊。\n",
            "\n",
            "62 Linux kernel 的完全公平排程器 (CFS) 使用紅黑樹來儲存排序相關資訊。\n",
            "題目:諾曼第登陸作戰的代號是什麼？\n",
            "summarize:\n",
            "\n",
            "諾曼第登陸作戰的代號是霸王行動（Operation Overlord）。\n",
            "\n",
            "霸王行动（Operation Overlord）是盟军于1944年6月发动的诺曼底登陆作战，代号为“D日”或海洋之星。该次战斗标志着第二世界大戰西方戦線的一個重要轉折點，是美軍和英國在歐洲的大規模進攻行動。\n",
            "\n",
            "霸王行动是盟军远征部队最高司令德怀特·艾森豪威尔的指挥下，美国、英国及其他同联盟国共同发动的一个大规模两栖作战。该次战斗目的是夺取诺曼底地区，并从此向东推进至巴黎和法国北方。\n",
            "\n",
            "盟军在行动前进行了大量准备工作，其中包括空降突袭，海上炮击及登陆艇的部署。在D日当天（1944年6月5号），近132,000名士兵乘船或机器横渡英吉利 海峡，并于早晨开始攻击诺曼底地区。盟军在行动中遭遇了德国守軍頑強抵抗，但最终仍成功夺取并控制整个海滩。\n",
            "\n",
            "霸王行動的胜负对第二世界大戰西方战线产生重大影响，标志着美、英等国家开始向欧洲推进，并逐渐将纳粹德国赶出法国北部。\n",
            "\n",
            "諾曼底登陸作戰的代號是D日（Operation Overlord），這是一項規模最大的軍事行動，盟國在1944年6月5-7日期間發起對德意志第三帝国内法蘭西北部海岸地區進行的大型攻勢。\n",
            "\n",
            "63 霸王行動（Operation Overlord）\n",
            "題目:《Cytus II》遊戲中「Body Talk」是哪位角色的歌曲？\n",
            "summarize:\n",
            "\n",
            "《Cytus II》遊戲中「Body Talk」是PAFF的歌曲。\n",
            "\n",
            "《Cytus II》遊戲中「Body Talk」是PAFF的歌曲。\n",
            "\n",
            "《Cytus II》遊戲中「Body Talk」是PAFF的歌曲。\n",
            "\n",
            "64 PAFF的歌曲。\n",
            "題目:李琳山教授的演講又被稱為什麼？\n",
            "summarize:\n",
            "\n",
            "李琳山教授的演講又被稱為「信號與人生」。\n",
            "\n",
            "65 「信號與人生」。\n",
            "題目:RTX 5090 顯卡的 VRAM 是多少？\n",
            "summarize:\n",
            "\n",
            "根據提供的資訊，RTX 5090 顯卡是 NVIDIA 的一款高性能顯示核心，但在文中並未直接提及 RTx-50系列VRAM容量。\n",
            "\n",
            "你被網路安全阻擋了，若要繼續，你可以登入你的Reddit帳號或使用開發者令牌。如果覺得是誤判，可以在下方提交一個檔案票據，我們會檢查看看。\n",
            "\n",
            "你被網路安全阻擋了，若要繼續，你可以登入你的Reddit帳號或使用開發者令牌。如果覺得是誤判，可以在下方提交一個檔案票據，我們會檢查看看。\n",
            "\n",
            "66 根據我的知識，RTX 5090 顯卡的 VRAM容量並未在提供資訊中明確提及。\n",
            "題目:2024年世界棒球12強賽冠軍為哪一隊？\n",
            "summarize:\n",
            "\n",
            "2024年世界棒球12強賽冠軍為台灣隊。\n",
            "\n",
            "2024年世界棒球12强赛中华台北代表队夺得冠军，这是他们首次在国际一级比赛中获得金牌，也终止了日本的27连胜纪录。\n",
            "\n",
            "2024年世界棒球12強賽冠軍為中華隊。\n",
            "\n",
            "67 日本隊。\n",
            "題目:中國四大奇書是哪幾本？\n",
            "summarize:\n",
            "\n",
            "中國四大奇書是指章回小說《水滸傳》、《三國演義》，以及馮夢龍所定的另外兩本作品： 《西遊記 》和 　金瓶梅。\n",
            "\n",
            "四大名著是指中国文学史上具有代表性的章回小说，包括《三国演义》、《水滸传》，以及后来取代的两部作品：最初为「金瓶梅」，後來被紅樓夢所替換。\n",
            "\n",
            "四大奇書是指中國古典小說中的《水滸傳》、《三國演義 》、 《金瓶梅》，以及西遊記。\n",
            "\n",
            "68 《水滸傳》、《三國演義》，以及馮夢龍所定的另外兩本作品： 《西遊記 》和 　金瓶梅。\n",
            "題目:中國時辰中的子 時，如果用24小時間制表示，是幾點到几点？\n",
            "summarize:\n",
            "\n",
            "根據題目和文章敘述，子時在二十四小時間制中對應的时间是00:01到 1 小时。\n",
            "\n",
            "根據題目和文章敘述，子時在24小時間制中，是從23點到1点。\n",
            "\n",
            "根據題目和敘述，我們可以得出以下結論：在24小時間制中，子時對應的时间是23點到1点。\n",
            "\n",
            "69 根據題目和文章敘述，我們可以得出以下結論：在24小時間制中，子時對應的时间是23點到1点。\n",
            "題目:在作業系統中，避免要錯過時限來完成任務的排程演算法稱為什麼？\n",
            "summarize:\n",
            "\n",
            "在作業系統中，避免錯過時限來完成任務的排程演算法稱為Deadline Scheduling。 DeadlineScheduing是一種實現即使時間限制內對事件做出反應的一類特殊型別之Real-timeoperatingsystem（RTOS），其特性是必須在精確且有限定的时间内对某些任务或操作进行处理和响应，從而達到最短的延遲。 Deadline Scheduling主要目標不是高吞吐量，而是在保證任務完成時間內使得系統能夠以預期之時限對事件做出反應。\n",
            "\n",
            "DeadlineScheduing可以分為兩類：Softreal-time和Hard real time，前者是指在截止时间内尽可能地处理任务，但如果无法按时结束，也不会造成严重后果；而後者的硬实 时系统则要求必须按照预定的 deadline 完成所有的操作，如果延迟了，就会导致整个系統崩溃。\n",
            "\n",
            "Linux核心中提供了一種Deadline Scheduling演算法，稱為SCHED_DEADLINE，它是一個基於Earliest Deadline First（EDF）的實現。該策略會根據任務截止時間來進行排程，每次選擇具有最早的deadline值得優先執行。\n",
            "\n",
            "在Linux核心中，這種Deadline Scheduling演算法與其他Real-time Scheduler有所區別，例如POSIX RealtimeScheduler和Constant Bandwidth Server（CBS）。 DeadlineScheduing可以有效地避免錯過時限來完成任務，並且能夠保證系統的即使性。\n",
            "\n",
            "在作業系統中，避免錯過時限來完成任務的排程演算法稱為可搶先（Preemptive）或動態優化。\n",
            "\n",
            "排程（Schedule）是指為了提供多使用者及服務的對象很多時，需要安排順序來執行這些需求。因此，在作業系統中避免錯過時間限制完成任務所用的演算法稱之爲「就緒狀態下的哪個程序可以進入實施中的排程」。\n",
            "\n",
            "70 Deadline Scheduling。\n",
            "題目:《刀劍神域》中，「C8763」招式代號對應哪位角色持有的剑技？\n",
            "summarize:\n",
            "\n",
            "《刀劍神域》中，「C8763」招式代號對應的是桐人所使用的剑技——星光連流擊（Starburst Stream）。\n",
            "\n",
            "根據題目，「C8763」是《刀劍神域》中的一個招式代號。這種情況通常與角色技能或特殊能力相關。在本文的內容之間，我們找到了關於SAO和AW系列動畫討論串，但沒有直接提到該問題。但是在題目所指的是《加速世界》，而不是刀劍神域，所以我們需要在這個板塊中尋求答案。\n",
            "\n",
            "根據相關資訊，「C8763」是黑雪姬的招式代號。\n",
            "\n",
            "根據題目《刀劍神域》中，「C8763」招式代號對應哪位角色持有的剑技？這個問題與給出的敘述無關。因此，我們需要從其他資源或內容來找到答案。\n",
            "\n",
            "然而，如果要在提供的文本找出相關信息，那麼我只能說，這些是Google公司網站的一部分，沒有任何有用的情報可以幫助我們回答題目中的問題。但如果你能給予更多關於《刀劍神域》或其他資源，我們就更容易找到答案。\n",
            "\n",
            "71 黑雪姬。\n",
            "題目:《斯卡羅》劇中之地名「柴城」位於現今的哪個行政區劃？\n",
            "summarize:\n",
            "\n",
            "《斯卡羅》劇中之地名「柴城」位於現今的屏東縣車埕鄉。\n",
            "\n",
            "《斯卡羅》劇中之地名「柴城」位於現今的屏東縣。\n",
            "\n",
            "《斯卡羅》劇中之地名「柴城」位於現今的屏東縣車埕鄉。\n",
            "\n",
            "72 《斯卡羅》劇中之地名「柴城」位於現今的屏東縣車埕鄉。\n",
            "題目:Google Colab Pro+與Colaboratory的Pro版有何不同？\n",
            "summarize:\n",
            "\n",
            "根據題目和敘述，我們可以知道 Google Colab Pro+ 和Colaboratory的Pro版是付費服務。雖然沒有明確提到定價，但我們仍能夠做出一些推測。\n",
            "\n",
            "Google 的雲端計算平台通常會提供免 phí版本，同時也有一些高級功能和額外儲存空間等優惠給予使用者購買 Pro 版本的付費服務。因此，我們可以假設 Google Colab 也是如此：Pro+ 和Colaboratory's PRO版可能包含一些進階特性、更多資源或更大的資料上傳限制，相比於免 phí版本。\n",
            "\n",
            "然而，因為題目和敘述並未提供明確的定價信息，因此我們無法得知 Pro 版本與 Colab 付費服務之間具體差異。\n",
            "\n",
            "Google Colab Pro+與Colaboratory的Pro版有以下不同之處：\n",
            "\n",
            "1. 連線時間限制：免費版本（包括原來稱為「Free」和新推出的 「Basic」的層級）的使用者只能在12小時內執行一次Notebook，然後需要重新啟動。另一方面，在Colab Pro+中，您可以持續24個 小 時連線。\n",
            "2.  GPU資源：免費版本的GPU分配可能會因為伺服器負載而有所變化，而 Colaboratory 的Pro版則提供更穩定的和可預測性的硬體加速。 \n",
            "3\\. 記憶體回收限制: 免费层级通常只有12-16GB RAM，Colab Pro+ 提供更多的RAM，但仍然有限制。\n",
            "4.  儲存空間：免費版本有70 GB 的儼量，而 ColaboratoryPro版則提供更大的硬碟容積。\n",
            "\n",
            "總而言之，用Google Collaboarator進行AI模型訓練時，需要了解其限制並根據自己的需求選擇合適的解決方案。如果您遇到記憶體不足或其他問題，可以嘗試以下方法：減少BatchSize、縮小模式大小等。\n",
            "\n",
            "根據題目，Google Colab Pro+與Colaboratory的Pro版之間主要區別在於安全性和限制。雖然兩者都提供了高級功能，但 Google 會對使用者的網路行為進行監控，並可能阻止某些操作以維持系統穩定。如果你被鎗住，需要登入你的 Reddit 帳號或是用開發人員金鑰來解除限制。\n",
            "\n",
            "73 Google Colab Pro+與Colaboratory的Pro版有以下不同之處：  1. 連線時間限制：免費版本只能在12小時內執行一次Notebook，然後需要重新啟動，而 Google Collaboarator 的 PRO 版可以持續24個 小 時。 2\\. GPU資源: 免费层级的GPU分配可能會因為伺服器負載而有所變化，但 Colaboratory Pro版則提供更穩定的和可預測性的硬體加速。  3. 記憶體回收限制：免費版本通常只有12-16GB RAM，而 Google Collaboarator 的 PRO 版本 提供更多的RAM。 4\\. 儲存空間: 免费层级有70 GB儼量，但 Colaboratory Pro版則提供更大的硬碟容積。\n",
            "題目:李宏毅老師開設的機器學習課程，屬於哪個學院？\n",
            "summarize:\n",
            "\n",
            "李宏毅老師開設的機器學習課程屬於台湾大学電机工程学系。\n",
            "\n",
            "根據題目和敘述，我們可以知道李宏毅老師開設的機器學習課程。\n",
            "\n",
            "李宏毅老師開設的機器學習課程，屬於台大電氣工程學院。\n",
            "\n",
            "74 台大電氣工程學院。\n",
            "題目:就讀國立臺灣大學資工系的大三學生，需要修多少分才不用簽減免申請書？\n",
            "summarize:\n",
            "\n",
            "根據題目和敘述，國立臺灣大學資工系的大三學生需要修多少分才不用簽減免申請書？ \n",
            "\n",
            "答：依照提供的資料，這個問題並未直接提及具體數值，但可以看出相關規定與時間安排。\n",
            "\n",
            "台大資工系的大三學生，通常需要修滿一定的分數才不用簽減免申請書。根據提供的一些資料和注意事項，我們可以知道：\n",
            "\n",
            "* 台大的新鮮人一般可選課15~25個科目。\n",
            "由於題目的具體要求是大3，所以我們要找出台大學生修滿一定分數才不用簽減免申請書的資訊。根據提供的一些資料和注意事項，我們可以知道：\n",
            "\n",
            "* 台大的學費一般會有部分可抵扣或補助。\n",
            "由於題目的具體要求是大3，所以我們要找出台大學生修滿一定分數才不用簽減免申請書的資訊。根據提供的一些資料和注意事項，我們可以知道：\n",
            "\n",
            "* 台大的學費一般會有部分可抵扣或補助。\n",
            "由於題目的具體要求是大3，所以我們要找出台大學生修滿一定分數才不用簽減免申請書的資訊。根據提供的一些資料和注意事項，我們可以知道：\n",
            "\n",
            "* 台大的學費一般會有部分可抵扣或補助。\n",
            "由於題目的具體要求是大3，所以我們要找出台大學生修滿一定分數才不用簽減免申請書的資訊。根據提供的一些資料和注意事項，我們可以知道：\n",
            "\n",
            "* 台大的學費一般會有部分可抵扣或補助。\n",
            "由於題目的具體要求是大3，所以我們要找出台大學生修滿一定分數才不用簽減免申請書的資訊。根據提供的一些資料和注意事項，我們可以知道：\n",
            "\n",
            "* 台大的學費一般會有部分可抵扣或補助。\n",
            "由於題目的具體要求是大3，所以我們要找出台大學生修滿一定分數才不用簽減免申請書的資訊。根據提供的一些資料和注意事項，我們可以知道：\n",
            "\n",
            "* 台大的學費一般會有部分可抵扣或補助。\n",
            "由於題目的具體要求是大3，所以我們要找出台大學生修滿一定分數才不用簽減免申請書的資訊。根據提供的一些資料\n",
            "\n",
            "根據題目，國立臺灣大學資工系的大三學生需要修多少分才不用簽減免申請書？雖然文中沒有明確提到這個問題的答案，但是可以從相關內容推測出來。一般而言，大一、大二和大三年級在台大的平均成績約為85-90，若要避開需要填寫學生資助方案申請書（減免），通常需達80分以上。但是，這個數字可能會因系所、年份等不同情況而有變化。\n",
            "\n",
            "75 大三學生通常需要修滿80分以上才不用簽減免申請書。\n",
            "題目:知名 AI VTuber「Neuro-sama」最初的 Live2D 模型是使用 VTube Studio 的哪個角色？\n",
            "summarize:\n",
            "\n",
            "Neuro-sama最初的Live2D模型是使用VTube Studio中的角色「桃瀨日和／ 桃瀬ひより」作為形象（VT1）。\n",
            "\n",
            "根據題目，知名 AI VTuber「Neuro-sama」最初的 Live2D 模型是使用 VTube Studio 的桃瀨日和角色。\n",
            "\n",
            "這些敘述與題目無關，似乎是 Google 的網站內容。因此，我們需要找到有用的資訊來回答問題。\n",
            "\n",
            "根據我的知識庫中找到的資料：Neuro-sama 是一位日本 VTuber，她的最初 Live2D 模型其實是在 VTube Studio 中使用了「VTubee」角色模板創建而成，之後才進行修改和個人化。\n",
            "\n",
            "76 Neuro-sama 的最初 Live2D 模型是使用 VTube Studio 中的「VTubee」角色模板創建而成。\n",
            "題目:從零開始的異世界生活 第三季中，劫持愛蜜莉雅並想取其為妻的人是誰？\n",
            "summarize:\n",
            "\n",
            "劫持愛蜜莉雅並想取其為妻的人是羅茲瓦爾·L・梅札斯。\n",
            "\n",
            "劫持爱蜜莉娅并想取其为妻的人是尤里乌斯·阿斯特雷亚。\n",
            "\n",
            "這個敘述與題目無關，主要是Google的網站內容。\n",
            "\n",
            "77 尤里乌斯·阿斯特雷亚。\n",
            "題目:《海綿寶宝》第五季中，主角在哪個城市擊敗刺破泡沫紅眼幇？\n",
            "summarize:\n",
            "\n",
            "《海綿寶宝》第五季中，主角在紐開普市擊敗刺破泡沫紅眼幇。\n",
            "\n",
            "根據題目和敘述，我們可以知道《海綿寶宝》第五季中，主角在哪個城市擊敗刺破泡沫紅眼幇。然而，因為沒有提供相關的文本描述，所以無法直接進行總結。但是，如果你能夠給出一些關於ML2025Homework1|Kaggle 的敘述，我們就可以根據這些信息來做一個合理的地推或猜測了。\n",
            "\n",
            "如果有任何額外資訊，請提供我相關的文本描述。\n",
            "\n",
            "《海绵宝寶》第五季中，主角在布鲁克菲尔德广场（Brookfield Place）击败刺破泡沫红眼幇。\n",
            "\n",
            "78 紐約市\n",
            "題目:玉米是單子葉還是不雙子的植物？\n",
            "summarize:\n",
            "\n",
            "玉米是一种单子叶植物，属于禾本科。\n",
            "\n",
            "根據文章的敘述，玉米是一種單子葉植物。\n",
            "\n",
            "根據題目和敘述，我們可以得出以下結論：玉米是一種單子葉植物。\n",
            "\n",
            "79 玉米是一種單子葉植物。\n",
            "題目:中華民國陸軍的前六字是什麼？\n",
            "summarize:\n",
            "\n",
            "中華民國陸軍的前六字是「忠誠親愛精」。\n",
            "\n",
            "中華民國陸軍的前六字是「忠誠衛護」。\n",
            "\n",
            "80 忠誠衛護\n",
            "題目:台大電資學院哪個系規定物理、化學以及生物科目的選修？\n",
            "summarize:\n",
            "\n",
            "台大電資學院規定物理、化學以及生物科目的選修，分為以下幾類：\n",
            "\n",
            "1. ³qÃÑ¤Æ¾Ç¨t：包括´¶３ｑＧＡＥＣＳ和¦X¬ì¥Ø。\n",
            "2.»O¤¤°ê»Ú­nª`·N¡GºÓ/3Õh¯Z\n",
            "   - ¬ãÅs ¥Í(96-105) \n",
            "     1. »Ý±µ¨ü6¤p®ÉÀô ¦w½Ã (j)\n",
            "       ¡u¦M ÀI¬ì¥Ø³q識 ±Ð°V 練¡v3\n",
            "      - j: ¬ãÅs ¥Í(96-105) \n",
            "     2. »Ý±µ¨ü6¤p®ÉÀô ¦w½Ã (k)\n",
            "       ¡u¦@¯ë¬ì¥Ø³q識 ±Ð°V 練¡v3\n",
            "      - k: ¬ãÅs ¥Í(96-105) \n",
            "   2. µL¾÷ª«¤Æ¨tÀô ¦w½Ã (l)\n",
            "     ¡uµ{ «×¬ì¥Ø³q識 ±Ð°V 練¡v3\n",
            "      - l: ¬ãÅs ¥Í(96-105) \n",
            "   2. µL¾÷ª«¤Æ¨tÀô ¦w½Ã (m)\n",
            "     ¡uµ{ «×¬ì¥Ø³q識 ±Ð°V 練¡v3\n",
            "      - m: ¬ãÅs ¥Í(96-105)\n",
            "\n",
            "根據題目和文章敘述，台大電資學院規定物理、化學以及生物科目的選修。\n",
            "\n",
            "根據題目和敘述，台大電資學院的物理、化學以及生物科目的選修是由於大學採計APCS之校系查詢：https://apcs.csie.ntnu.edu.tw/index.php/apc...\n",
            "\n",
            "81 根據題目和文章敘述，台大電資學院規定物理、化學以及生物科目的選修。\n",
            "題目:憂傷湖、死lake 、忘記Lake  和恐怖Lacus 以及愛灣何者位於不面對地球的月球背面的地形？\n",
            "summarize:\n",
            "\n",
            "憂傷湖（LacusDoloris）、死lake （誤植，應該是 LacusMorti s），忘記Lake  (Oblivion) 和恐怖lacuS 以及愛灣SinusuAmoris 位於月球正面的地形。\n",
            "\n",
            "82 愛灣SinusuAmoris\n",
            "題目:貝多芬《C♯小調第14號鋼琴奏鳴曲》較為人知的別稱是什麼？\n",
            "summarize:\n",
            "\n",
            "83 《C♯小調第14號鋼琴奏鳴曲》較為人知的別稱是「月光 Sonata」。\n",
            "題目:阿米斯音樂節是由哪位歌手所舉辦？\n",
            "summarize:\n",
            "\n",
            "阿米斯音樂節是由舒美恩（Suming）與都蘭部落族人共同創辦的，以原住民族文化為主體的一年一度音乐节。該活動每三年舉行一次，通常在台東縣 都兰 的中旬左右進行，每屆均有多種形式和內容，並由各參加團隊負責呈現。此外，這個音樂節還有一面特色旗幟，即阿米斯音楽祭-國籍（AmisMusicFestival），該項活動已經被原住民族電視台記錄並入選英格蘭的第12屆Native Spirit Festival。\n",
            "\n",
            "阿米斯音樂節的舉辦者無法確認。\n",
            "\n",
            "阿米斯音樂節是由舒美恩（Suming）所創辦的。\n",
            "\n",
            "84 舒美恩（Suming）\n",
            "題目:Poppy Playtime - Chapter 4 中的黏土人叫甚麼名字？\n",
            "summarize:\n",
            "\n",
            "Poppy Playtime - Chapter 4 中的黏土人叫做 Yarnaby。\n",
            "\n",
            "根據題目與敘述，我們可以發現這些內容其實是Google的網站頁面。然而，關於Poppy Playtime - Chapter 4 中黏土人名字並沒有在此處找到相關資訊。但如果你需要知道答案，可以試著查找其他有用的資料或是在遊戲中觀察一下角色名稱可能會更好！\n",
            "\n",
            "85 我找不到相關資訊，可能需要在遊戲中觀察角色名稱。\n",
            "題目:賓茂村屬於哪一行政區劃？\n",
            "summarize:\n",
            "\n",
            "賓茂村位於臺東縣金峰鄉，是該地區的一個飛地，同時也被認為是西元1951年（民國40 年）遷居後建立的新聚落。\n",
            "\n",
            "賓茂村屬於金峰鄉行政區域，但其所在地周圍卻是由太麻里乡管轄。\n",
            "\n",
            "賓茂村屬於金峰山地鄉管轄，儘然它的位置在太麻里 Township內。\n",
            "\n",
            "86 賓茂村屬於金峰鄉行政區域。\n",
            "題目:義大利文藝復興時期著名雕塑家米開朗基羅創作的《大衛》最初是在哪裡展出？\n",
            "summarize:\n",
            "\n",
            "米開朗基羅的《大衛》雕像最初是在佛罗伦萨市政厅旧宫入口展出。\n",
            "\n",
            "米開朗基羅的《大衛》最初是在佛罗伦萨市政厅舊宮入口展出。\n",
            "\n",
            "米開朗基羅的《大衛》雕像最初是在佛罗伦萨圣马可广场展出。\n",
            "\n",
            "87 米開朗基羅的《大衛》最初是在佛罗伦萨市政厅舊宮入口展出。\n",
            "題目:除了蔣中正之外，曾短暫晉升特級上將的另一位軍事領袖是誰？\n",
            "summarize:\n",
            "\n",
            "根據題目和文章敘述，除了蔣中正之外，被授予特級上將軍銜的另一位人物是無法確定，因為文獻並未提及其他任何人曾經獲得這一榮譽。\n",
            "\n",
            "除了蔣中正之外，曾短暫晉升特級上將的另一位軍事領袖是馮·施利芬伯爵。\n",
            "\n",
            "根據題目和文章敘述，除了蔣中正之外曾短暫晉升特級上將的另一位軍事領袖是閻錦山。\n",
            "\n",
            "88 馮·施利芬伯爵\n",
            "題目:2012年英雄聯盟世界大賽總冠軍是哪個戰隊？\n",
            "summarize:\n",
            "\n",
            "2012年英雄聯盟世界大賽的冠軍是台北暗殺星（Taipei Assassins），他們在決勝戰中以3比1擊敗韓國隊伍Azubu Frost，獲得了100萬美元獎金和一座錦標。\n",
            "\n",
            "2012年英雄联盟世界大赛总冠军是台北暗杀星。\n",
            "\n",
            "2012年英雄聯盟世界大賽的冠軍是萌娘百科未能提供相關資訊，但根據題目，我們可以推測該戰隊應為勝出者。\n",
            "\n",
            "89 答案：台北暗殺星（Taipei Assassins）\n",
            "題目:在日本麻將中，非莊家一開始的手牌有幾張？\n",
            "summarize:\n",
            "\n",
            "日本麻将的非莊家一开始的手牌有13张。\n",
            "\n",
            "日本麻将中，非莊家一開始的手牌有13張。\n",
            "\n",
            "日麻的非莊家一開始的手牌有13張。\n",
            "\n",
            "90 13張\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the results into one file.\n",
        "with open(f'./{STUDENT_ID}.txt', 'w') as output_f:\n",
        "    for id in range(1,91):\n",
        "        with open(f'./{STUDENT_ID}_{id}.txt', 'r') as input_f:\n",
        "            answer = input_f.readline().strip()\n",
        "            print(answer, file=output_f)"
      ],
      "metadata": {
        "id": "GmLO9PlmEBPn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}